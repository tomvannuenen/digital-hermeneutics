{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WClw_VPOmwXd"
   },
   "source": [
    "<div style=\"display: block; width: 100%; height: 120px;\">\n",
    "\n",
    "<p style=\"float: left;\">\n",
    "    <span style=\"font-weight: bold; line-height: 24px; font-size: 16px;\">\n",
    "        DIGHUM160 - Critical Digital Humanities\n",
    "        <br />\n",
    "        Digital Hermeneutics\n",
    "    </span>\n",
    "    <br >\n",
    "    <span style=\"line-height: 22x; font-size: 14x; margin-top: 10px;\">\n",
    "        Week 1: Introduction <br />\n",
    "        Created by Tom van Nuenen (tom.van_nuenen@kcl.ac.uk)\n",
    "    </span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36-_8ZvxmwXf"
   },
   "source": [
    "# Welcome!\n",
    "\n",
    "In this notebook we will go over some basic operations in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YUirSNPmwXf"
   },
   "source": [
    "## 1. Working with .txt files\n",
    "\n",
    "Write a small utility function `read_file(filename)` that reads a specified file and simply returns all contents as a single string. Use it to read the example file 'test.txt' and save it in the variable `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuiuknq0cMe3"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q6Ih4fo9gax5"
   },
   "source": [
    "Make sure you have the test.txt file in your Google Drive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "Fr8bu07_cOQ0",
    "outputId": "00e64697-25b3-4785-bb18-6f5c3e971f6d"
   },
   "outputs": [
    {
     "ename": "FileNotDownloadableError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotDownloadableError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cb61994fcaf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdownloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"1D7HcdsFdgR8ofCG33YlP4NGthVq23mMh\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdownloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetContentFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mGetContentFile\u001b[0;34m(self, filename, mimetype, remove_bom)\u001b[0m\n\u001b[1;32m    208\u001b[0m                     \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_bom\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchContent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36m_decorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecoratee\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_decorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mFetchContent\u001b[0;34m(self, mimetype, remove_bom)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       raise FileNotDownloadableError(\n\u001b[0;32m--> 265\u001b[0;31m         'No downloadLink/exportLinks for mimetype found in metadata')\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmimetype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'text/plain'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotDownloadableError\u001b[0m: No downloadLink/exportLinks for mimetype found in metadata"
     ]
    }
   ],
   "source": [
    "downloaded = drive.CreateFile({'id':\"1D7HcdsFdgR8ofCG33YlP4NGthVq23mMh\"})   \n",
    "downloaded.GetContentFile('test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "FRJWdiHZccli",
    "outputId": "c712458b-2dc0-44a7-b72f-b4e65f4514f0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-63f5907116cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdownloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"1D7HcdsFdgR8ofCG33YlP4NGthVq23mMh\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'drive' is not defined"
     ]
    }
   ],
   "source": [
    "downloaded = drive.CreateFile({'id' : \"1D7HcdsFdgR8ofCG33YlP4NGthVq23mMh\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_i6-ZX6mmwXg"
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    \"Read the contents of FILENAME and return as a string.\"\n",
    "    # insert your code here\n",
    "\n",
    "    \n",
    "    \n",
    "# this should work if your code is correct\n",
    "test = read_file('test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RT6CadvjmwXl"
   },
   "source": [
    "Now, we are going to create a function `split_sentences` that performs some very simple sentence splitting when passed a text string. Each sentence will be represented as a new string, so the function as a whole returns a list of sentence strings. We assume that any occurrence of either  . or ! or ? marks the end of a sentence.\n",
    "\n",
    "First, we'll create a function called `end_of_sentence_marker` that takes as argument a character and returns True if it is an end-of-sentence marker, otherwise it returns False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mLFgg9QTmwXl"
   },
   "outputs": [],
   "source": [
    "# Define your function here\n",
    "def end_of_sentence_marker(character):\n",
    "    # insert your code here\n",
    "\n",
    "    \n",
    "\n",
    "# these tests should return True if your code is correct\n",
    "print(end_of_sentence_marker(\"?\") == True)\n",
    "print(end_of_sentence_marker(\"a\") == False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BemPS6vLmwXo"
   },
   "source": [
    "An important function we will use is the built in `enumerate`. `enumerate` takes as argument any iterable (a string a list etc.). Let's see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOl58CxjmwXp"
   },
   "outputs": [],
   "source": [
    "for i, character in enumerate(\"Python\"):\n",
    "    print(i, character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onXIjY0SmwXs"
   },
   "source": [
    "As we can see, enumerate allows us to iterate over an iterable and for each element in that iterable, it gives us its corresponding index. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyEfG_65mwXs"
   },
   "source": [
    "Now we can create our function `split_sentences`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqcaAMPmmwXt"
   },
   "outputs": [],
   "source": [
    "def split_sentences(text):\n",
    "    \"Split a text string into a list of sentences.\"\n",
    "    sentences = []\n",
    "    start = 0\n",
    "    for end, character in enumerate(text):\n",
    "        if end_of_sentence_marker(character):\n",
    "            sentence = text[start: end + 1]\n",
    "            sentences.append(sentence)\n",
    "            start = end + 1\n",
    "    return sentences\n",
    "\n",
    "split = split_sentences(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ggUeYWSmwXw"
   },
   "source": [
    "Within `split_sentences`, we define a variable 'sentences' in which we store the individual sentences. Next, we define a variable `start` and set it to zero. We're doing this as we need to extract both the start position and the end position of each sentence, and we know that the first sentence will always start at position 0.\n",
    "\n",
    "Next, we use `enumerate` to *loop* over all individual characters in the text. Remember that enumerate returns pairs of indexes and their corresponding elements (here characters). For each character we check whether it is an end-of-sentence marker. If it is, the variable end marks the position in text where a sentence ends. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVXkXvx8mwXw"
   },
   "source": [
    "There is an easier way to do this, however, which is through NLTK. We will use the `sent_tokenize` package, import it, and run it on our `test` data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ObxTV_7_mwXx"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QklXaMOgmwXz"
   },
   "source": [
    "Finally, let's visualize some of these results. We'll create a new variable called `sentence_length`, assigning an empty list to it. We'll then loop over our `split` variable (which contains all split sentences in our test file) and add the length of each sentence to the `sentence_length` variable (tip: use the built-in `len()` function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ForANRI1mwX0"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBdsaP2RmwX3"
   },
   "source": [
    "Finally, we'll import matplotlib and plot `sentence_length`. If you did everything right, the below code should give you a graph of the sentence lengths!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cAxAJwvimwX4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(sentence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NgBDYstgmwX6"
   },
   "source": [
    "## 2. Working with Pandas\n",
    "\n",
    "Next, we'll import a .csv into a Pandas dataframe. But first we have to get it. One way to do this is by using PyDrive. We need to authenticate ourselves to Google so we can access a unique file ID on our Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnrwoPhVEs_z"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACZjMnD0E3B3"
   },
   "source": [
    "Next, locate the file using its ID (to find the ID, go to your Drive folder, right-click on the file you want the ID of, and click \"Get shareable link\". The ID can be found in the link the Google gives you. For instance, in this link:\n",
    "\n",
    "```\n",
    "https://drive.google.com/file/d/1v2SYkCtIX6Pwg7rZyb25-Z2olLI8eNf_/view?usp=sharing\n",
    "```\n",
    "\n",
    "The ID is everything between the two forward brackets after `d/` and before `/view`. So: `1v2SYkCtIX6Pwg7rZyb25-Z2olLI8eNf_`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BFgs1xhj1V9o"
   },
   "outputs": [],
   "source": [
    "downloaded = drive.CreateFile({'id':\"1fOe3l9dLKb51jrwqUNOvwO4A7F7sM6Xx\"})   # replace the id with id of file you want to access\n",
    "downloaded.GetContentFile('seduction-submissions.csv')       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rc4PDVYGBjie"
   },
   "source": [
    "Alternatively, you can use the `drive' method to \"mount\" your Google Drive within this notebook (meaning you can access all your files from there)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "h7Cd_Ze8BfIs",
    "outputId": "7e6e000d-1c55-4bc1-d802-d8cdb601b1b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKckZ1DREBmJ"
   },
   "source": [
    "We can now navigate within our Google Drive folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "BWrHsWO2Bhii",
    "outputId": "33009d5e-032d-4b6b-ddf5-a1c290847dcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AskTrumpSupporters.csv\tmgtow_submissions.csv\t   TRP_comments.csv\n",
      "ferrante.txt\t\tseduction_submissions.csv  TRP_submissions.csv\n",
      "knaus.txt\t\ttest.txt\t\t   TRP_submissions_full.csv\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.chdir(\"/content/drive/My Drive/DIGHUM160-resources\") # You may need to change this to point to your location of the \"DIGHUM160-resources\" folder\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfgUmePwDb87"
   },
   "source": [
    "You can also use the Drive API to up- and download files to your Drive from a notebook, and so on. See https://colab.research.google.com/notebooks/io.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzhPGc5HEe7x"
   },
   "source": [
    "Next, we will import Pandas and use the read_csv function to open the example file. \n",
    "Then, show the first few lines of the dataframe (using the `.head()` function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 759
    },
    "id": "TkI-FuY2mwX6",
    "outputId": "40225fb0-0dc2-4271-e9eb-0833875d2b48",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no.</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/r/AskTrumpSupporters/co...</td>\n",
       "      <td>2018-10-22</td>\n",
       "      <td>MarsNirgal</td>\n",
       "      <td>13</td>\n",
       "      <td>Is there a control or solution for the things ...</td>\n",
       "      <td>Again, I'm assuming that there are things Trum...</td>\n",
       "      <td>AskTrumpSupporters is designed to provide a wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.reddit.com/r/AskTrumpSupporters/co...</td>\n",
       "      <td>2018-10-21</td>\n",
       "      <td>C137-Morty</td>\n",
       "      <td>239</td>\n",
       "      <td>Do you agree with Rand Paul that we should sto...</td>\n",
       "      <td>He said in an interview with Chris Wallace tha...</td>\n",
       "      <td>AskTrumpSupporters is designed to provide a wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.reddit.com/r/AskTrumpSupporters/co...</td>\n",
       "      <td>2018-10-21</td>\n",
       "      <td>56784rfhu6tg65t</td>\n",
       "      <td>7</td>\n",
       "      <td>Is the rise of groups like antifa a result of ...</td>\n",
       "      <td>Do you think groups like antifa would be as pr...</td>\n",
       "      <td>AskTrumpSupporters is designed to provide a wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.reddit.com/r/AskTrumpSupporters/co...</td>\n",
       "      <td>2018-10-21</td>\n",
       "      <td>ButAleppo</td>\n",
       "      <td>108</td>\n",
       "      <td>Trump is going to pull us out of a intermediat...</td>\n",
       "      <td>Read this on AOL: [https://www.aol.com/article...</td>\n",
       "      <td>AskTrumpSupporters is designed to provide a wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://www.reddit.com/r/AskTrumpSupporters/co...</td>\n",
       "      <td>2018-10-21</td>\n",
       "      <td>greyzcale</td>\n",
       "      <td>2</td>\n",
       "      <td>Do you have experience with MDMA/ecstacy, or o...</td>\n",
       "      <td>I've seen lots of liberal leaning people use M...</td>\n",
       "      <td>AskTrumpSupporters is designed to provide a wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>995</td>\n",
       "      <td>https://www.reddit.com/r/AskTrumpSupporters/co...</td>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>Hold_onto_yer_butts</td>\n",
       "      <td>444</td>\n",
       "      <td>If Michael Cohen provides clear evidence that ...</td>\n",
       "      <td>Michael Cohen is allegedly willing to testify ...</td>\n",
       "      <td>AskTrumpSupporters is designed to provide a wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>https://www.reddit.com/r/AskTrumpSupporters/co...</td>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>atsaccount</td>\n",
       "      <td>44</td>\n",
       "      <td>Did the White House lie about the weather?</td>\n",
       "      <td>http://thehill.com/homenews/administration/398...</td>\n",
       "      <td>AskTrumpSupporters is designed to provide a wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>https://www.reddit.com/r/AskTrumpSupporters/co...</td>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>EndlessSummerburn</td>\n",
       "      <td>274</td>\n",
       "      <td>President Trump's golf trips have cost about $...</td>\n",
       "      <td>I asked an NN this but would like to get more ...</td>\n",
       "      <td>AskTrumpSupporters is designed to provide a wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>https://www.reddit.com/r/AskTrumpSupporters/co...</td>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>throw_away_because08</td>\n",
       "      <td>60</td>\n",
       "      <td>Robert Mueller is reportedly looking into Trum...</td>\n",
       "      <td>Robert Mueller is reportedly([1](https://youtu...</td>\n",
       "      <td>AskTrumpSupporters is designed to provide a wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>https://www.reddit.com/r/AskTrumpSupporters/co...</td>\n",
       "      <td>2018-07-27</td>\n",
       "      <td>CumPoweredSteamBoat</td>\n",
       "      <td>126</td>\n",
       "      <td>This morning Trump tweeted that Twitter's shad...</td>\n",
       "      <td>[Here is the tweet in question](https://twitte...</td>\n",
       "      <td>AskTrumpSupporters is designed to provide a wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     no.  ...                                           comments\n",
       "0      1  ...  AskTrumpSupporters is designed to provide a wa...\n",
       "1      2  ...  AskTrumpSupporters is designed to provide a wa...\n",
       "2      3  ...  AskTrumpSupporters is designed to provide a wa...\n",
       "3      4  ...  AskTrumpSupporters is designed to provide a wa...\n",
       "4      5  ...  AskTrumpSupporters is designed to provide a wa...\n",
       "..   ...  ...                                                ...\n",
       "994  995  ...  AskTrumpSupporters is designed to provide a wa...\n",
       "995  996  ...  AskTrumpSupporters is designed to provide a wa...\n",
       "996  997  ...  AskTrumpSupporters is designed to provide a wa...\n",
       "997  998  ...  AskTrumpSupporters is designed to provide a wa...\n",
       "998  999  ...  AskTrumpSupporters is designed to provide a wa...\n",
       "\n",
       "[999 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"seduction-submissions.csv\") \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QuIFFo8clcwo"
   },
   "source": [
    "## Pandas basics & Working with Reddit data\n",
    "\n",
    "Using the `.head()` method we can get the first n rows of a df. The default is 5. We can add a *parameter* (here 3) to indicate how many rows we want to print."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zipTYx8rlbOo"
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9za2bgknrbRx"
   },
   "source": [
    "Here's what we're seeing. Pay special attention to the \"NaN\" labels, indicating missing values (we might want to get rid of them). Also remember the naming convention for the column and row axes (which Pandas uses when accessing particular rows/columns).\n",
    "![df](http://www.digitalhermeneutics.com/wp-content/uploads/2020/07/df.png)\n",
    "\n",
    "This particular dataset only includes the original posts in the subreddit (so not the comments on the posts). The \"selftext\" column contains the actual posts.\n",
    "\n",
    "other columns contain valuable metadata you can use in your analyses, such as: \n",
    "- \"created\" (the time of the post's creation)\n",
    "- \"score\" (amount of upvotes minus downvotes)\n",
    "- \"textlen\" (amount of words)\n",
    "- \"num_comments\" (the amount of comments)\n",
    "- \"flair_text\" (a 'tag' that users within a subreddit can add)\n",
    "- \"augmented_count\" (how often a user or moderator has edited the text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFzbshU1l7S5"
   },
   "outputs": [],
   "source": [
    "dfNew = df[:10].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHMTVlnAmwYB"
   },
   "source": [
    "## Tokenizing\n",
    "\n",
    "Now, we'll write a function `tokenizer()` that takes as input a string. There are lots of ways to do this, but here's one option.\n",
    "- turn the string into lower case \n",
    "- remove newlines and tabs using `translate`\n",
    "- clean up punctuation using `translate` and `string.punctuation`\n",
    "- put all words in a list after removing digits\n",
    "- return said list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5YGvN2GhmwYB"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def tokenizer(text):\n",
    "    '''cleans up and tokenizes input string'''\n",
    "    text = text.lower()\n",
    "    bad_chars = ['\\n', '\\t', '”', '“']\n",
    "    textClean = text.translate(str.maketrans({ch: \" \" for ch in bad_chars}))\n",
    "    table = str.maketrans({ch: None for ch in string.punctuation})\n",
    "    no_punct = (s.translate(table) for s in textClean.split(' ') if s != '')\n",
    "    digits_out = [word for word in no_punct if not word.isdigit()]       \n",
    "    return digits_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "k40LhROBj1Za",
    "outputId": "8241f7ba-de92-4e4e-ae3a-770085c395ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "def nltk_tokenizer(text): \n",
    "  tokens = nltk.word_tokenize(text)\n",
    "  lowers = tokens.lower()\n",
    "  return lowers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvtXxBUnmwYE"
   },
   "source": [
    "Next, we might want to use our tokenizer on only a subset of our data. Create a new dataframe which only contains the first 20 entries of our DataFrame. Also, remove all rows containing empty values (you can use Pandas' `dropna()` method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Tp6sayPmwYE"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "dfNew = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrK94GYTmwYH"
   },
   "source": [
    "Now let's run our tokenizer function, taking as input the `body` column from your dataframe. Loop over each row of your dataframe, and print out the tokenized `body` of each row to see if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "id": "_TApMXYHAMnR",
    "outputId": "468f41be-8db1-4bda-e502-803268189407"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['again', 'im', 'assuming', 'that', 'there', 'are', 'things', 'trumps', 'does', 'or', 'believes', 'that', 'even', 'his', 'supporters', 'dont', 'like', 'also', 'im', 'assuming', 'that', 'for', 'his', 'supporters', 'the', 'things', 'you', 'like', 'outweigh', 'the', 'things', 'you', 'dislike', 'so', 'overall', 'you', 'still', 'find', 'enough', 'reasons', 'to', 'support', 'him', 'still', 'it', 'would', 'be', 'nice', 'if', 'he', 'stopped', 'doing', 'the', 'things', 'you', 'dislike', 'while', 'continuing', 'with', 'the', 'things', 'you', 'like', 'wouldnt', 'it', 'so', 'what', 'would', 'be', 'a', 'good', 'strategy', 'to', 'prevent', 'him', 'from', 'doing', 'them']\n",
      "['he', 'said', 'in', 'an', 'interview', 'with', 'chris', 'wallace', 'that', 'we', 'need', 'to', 'stop', 'selling', 'arms', 'to', 'sa', 'and', 'that', 'we', 'shouldnt', 'view', 'arms', 'as', 'job', 'creation', 'but', 'rather', 'national', 'security', 'do', 'you', 'agree', 'with', 'pauls', 'view', 'how', 'do', 'you', 'feel', 'about', 'trumps', 'continued', 'support', 'for', 'sa', 'sourcehttpswwwgooglecomampswwwmediaitecomtvafterrandpaulblastssaudiexplanationasinsultingfoxschriswallaceaskshimwhytrumpbelievesitamp']\n",
      "['do', 'you', 'think', 'groups', 'like', 'antifa', 'would', 'be', 'as', 'prevalent', 'under', 'president', 'ted', 'cruz', 'or', 'president', 'marco', 'rubio', 'for', 'example', 'or', 'is', 'it', 'a', 'result', 'of', 'president', 'trump', 'would', 'any', 'republican', 'that', 'won', 'the', 'presidency', 'this', 'past', 'cycle', 'have', 'been', 'as', 'harshly', 'accused', 'of', 'being', 'a', 'facistnazibigotetc', 'also', 'this', 'may', 'be', 'too', 'broad', 'but', 'what', 'major', 'similarities', 'or', 'differences', 'do', 'you', 'think', 'we', 'would', 'see', 'on', 'the', 'political', 'climate', 'today', 'if', 'another', 'republican', 'had', 'been', 'elected', 'president']\n",
      "['read', 'this', 'on', 'aol', 'httpswwwaolcomarticlenews20181020trumpsaysuswillpulloutofintermediaterangenukepact23567011httpswwwaolcomarticlenews20181020trumpsaysuswillpulloutofintermediaterangenukepact23567011', 'x200b', 'apparently', 'its', 'been', 'in', 'place', 'since', 'and', 'both', 'russia', 'and', 'the', 'us', 'say', 'its', 'been', 'violated', 'by', 'both', 'parties', 'what', 'are', 'your', 'thoughts']\n",
      "['ive', 'seen', 'lots', 'of', 'liberal', 'leaning', 'people', 'use', 'mdmaecstasy', 'its', 'effects', 'commonly', 'include', 'increased', 'openmindedness', 'openheartedness', 'trust', 'empathy', 'etc', 'the', 'luvvy', 'duvvy', 'stuff', 'stuff', 'i', 'normally', 'think', 'of', 'as', 'being', 'hippie', 'stuff', 'i', 'dont', 'often', 'see', 'conservative', 'people', 'socially', 'and', 'i', 'dont', 'think', 'ive', 'ever', 'seen', 'a', 'conservative', 'take', 'mdmaecstacy', 'or', 'any', 'other', 'drug', 'known', 'to', 'have', 'similar', 'effects', 'is', 'it', 'at', 'all', 'normal', 'for', 'conservatives', 'to', 'use', 'such', 'drugs', 'recreationally', 'do', 'you', 'have', 'experience', 'with', 'this', 'or', 'similar', 'drugs', 'does', 'it', 'affect', 'how', 'you', 'view', 'other', 'people', 'do', 'you', 'feel', 'like', 'it', 'has', 'affected', 'your', 'worldview', 'at', 'all']\n",
      "['in', 'your', 'opinion', 'should', 'trump', 'fire', 'james', 'mattis', 'or', 'otherwise', 'pressure', 'him', 'to', 'leave', 'his', 'position', 'as', 'secretary', 'of', 'defense']\n",
      "['donald', 'trump', 'had', 'promoted', 'an', 'mlm', 'called', 'the', 'trump', 'networkhttpsenwikipediaorgwikithetrumpnetwork', 'from', 'do', 'you', 'believe', 'mlms', 'can', 'be', 'legitimate', 'businesses', 'do', 'you', 'consider', 'the', 'trump', 'network', 'a', 'positive', 'example', 'of', 'trumps', 'experience', 'or', 'just', 'a', 'mistake', 'that', 'isnt', 'serious', 'enough', 'to', 'keep', 'you', 'from', 'being', 'a', 'supporter']\n",
      "['if', 'you', 'keep', 'a', 'gun', 'at', 'home', 'the', 'standard', 'advice', 'is', 'to', 'keep', 'it', 'locked', 'up', 'perhaps', 'with', 'the', 'firing', 'pin', 'removed', 'or', 'some', 'other', 'safestorage', 'protocol', 'and', 'with', 'the', 'ammo', 'locked', 'up', 'separately', 'quite', 'a', 'lot', 'of', 'children', 'die', 'in', 'home', 'firearm', 'accidentshttpswwwibtimescomaccidentalgundeathsinvolvingchildrenaremajorproblemus2250568', 'so', 'responsible', 'storage', 'seems', 'like', 'a', 'good', 'idea', 'on', 'the', 'other', 'hand', 'one', 'reason', 'for', 'wanting', 'to', 'have', 'a', 'gun', 'in', 'the', 'home', 'in', 'the', 'first', 'place', 'is', 'so', 'you', 'can', 'defend', 'it', 'against', 'intruders', 'i', 'can', 'sympathise', 'with', 'this', 'desire', 'even', 'if', 'i', 'dont', 'think', 'a', 'gun', 'is', 'the', 'right', 'solution', 'but', 'if', 'you', 'are', 'a', 'responsible', 'gun', 'owner', 'who', 'keeps', 'their', 'gun', 'and', 'ammo', 'locked', 'up', 'separately', 'is', 'the', 'gun', 'actually', 'useful', 'for', 'home', 'defence', 'how', 'do', 'you', 'resolve', 'this', 'dilemma']\n",
      "['hypothetical', 'question', 'after', 'reading', 'httpswwwbusinessinsidercomjoescarboroughtrumpwontrunforreelectionin2020201810', 'if', 'trump', 'chooses', 'not', 'to', 'run', 'for', 'reelection', 'in', 'what', 'would', 'be', 'the', 'best', 'move', 'for', 'the', 'republican', 'party', 'who', 'would', 'be', 'his', 'successor', 'who', 'would', 'you', 'vote', 'for']\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "for row in dfNew['body']:\n",
    "   print(tokenizer(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a2w-4BvmwYJ"
   },
   "source": [
    "Next, we'll create the type-token ratio for each user in our df, to see whose language is the most 'complex'. First, we'll create a function for you that computes the TTR (see if you understand how it works!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8lo1Gz5hmwYJ"
   },
   "outputs": [],
   "source": [
    "def typeTokenRatio(tokens): \n",
    "    numTokens = len(tokens)\n",
    "    numTypes = len(set(tokens))\n",
    "    return numTypes/numTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPddUWELmwYM"
   },
   "source": [
    "Finally, loop over the 'body' column of each row in your df again. This time, within the loop, create a variable `tokens` and assign to it the output of your tokenizer function. Then, print the output of the `typeTokenRatio` function, which you run on `tokens`.\n",
    "\n",
    "If things go well, you'll see the TTR for each of the 20 posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xghYJeQ1mwYM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znmgu5ncmwYO"
   },
   "source": [
    "We see that some posts have a TTR of 1, meaning all words are unique. In fact, TTR does not tell us much here, as these are all short posts. But anyway: great work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdMGp8AomwYP"
   },
   "source": [
    "## Most-used words\n",
    "\n",
    "Next, we'll write a short program that tells you the *10 most-used words* for a given user comment in the DataFrame. We will use the `Counter` class from the `collections` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "5YUirSNPmwXf"
   ],
   "name": "1 Introduction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
