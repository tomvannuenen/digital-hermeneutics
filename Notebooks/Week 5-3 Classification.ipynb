{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Week 5-3 Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KAZIndhPZh2k",
        "0jMbvaKPZh3s",
        "_tAYGMaxZh37",
        "86yH3K8gZh37",
        "wH_tIIPyZh4m",
        "bOST9QEgZh42",
        "JLFyNfiSZh5M",
        "360smjSoZh5c",
        "eOIk4_iGZh5_",
        "Jddy_7cMZh6F"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7oOwS5XZh19",
        "colab_type": "text"
      },
      "source": [
        "<div style=\"display: block; width: 100%; height: 120px;\">\n",
        "\n",
        "<p style=\"float: left;\">\n",
        "    <span style=\"font-weight: bold; line-height: 24px; font-size: 16px;\">\n",
        "        DIGHUM160 - Critical Digital Humanities\n",
        "        <br />\n",
        "        Digital Hermeneutics 2020\n",
        "    </span>\n",
        "    <br >\n",
        "    <span style=\"line-height: 22x; font-size: 14x; margin-top: 10px;\">\n",
        "        Week 5-3: Classification<br />\n",
        "        Created by Tom van Nuenen (tom.van_nuenen@kcl.ac.uk)<br />\n",
        "    </span>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5tRlY3nZh1-",
        "colab_type": "text"
      },
      "source": [
        "#  Classification\n",
        "\n",
        "This extended notebook introduces some common methods for **classification**.\n",
        "Don't worry if you don't understand all of it – as long as you can see how classification might be valuable for your aims, that's enough!\n",
        "\n",
        "First, we’ll be using a Naive Bayes Classifier to differentiate between different \"classes\" of data. We will look at some tools for sentiment analysis. Finally, we'll combine these two methods, so we can see if we can predict positive and negative texts.\n",
        "\n",
        "After working through today's notebook, you will:\n",
        "\n",
        "1. understand how to use a **Naive Bayes classifier** using Reddit data;\n",
        "2. understand how to use a pre-trained sentiment analysis tool using **NLTK VADER**;\n",
        "3. understand how to train a Naive Bayes classifier for a **supervised class of sentiments** (i.e., creating and training your own sentiment analysis tool).\n",
        "\n",
        "Let's get started.\n",
        "\n",
        "\n",
        "## Introduction to Naive Bayes classifiers\n",
        "\n",
        "A Naive Bayes classifier is a machine learning algorithm that uses **Bayes’ Theorem** to predict the class that a sample belongs to, given a number of features that describe that sample. It is based on the concept of conditional probability: “What is the probability of our X, given Y?”. Which in our case is: \"What is the probability of a post belonging to a category, given its word frequencies?\" The math behind Bayes' Theorem is simple but intuitive. For more info, check out http://www.dealingdata.net/2016/07/24/PoGo-Series-NaiveBayesClassifier/.\n",
        "\n",
        "Naive Bayes classifiers are often considered the baseline for classification tasks. They have worked quite well in many real-world situations, famously document classification and spam filtering. Mathematically speaking, they are very straightforward, you can use them when you have limited resources in terms of CPU and memory. Further, when the training time is a crucial factor, Naive Bayes comes handy since it can be trained very quickly. \n",
        "\n",
        "One peculiar aspect of Naive Bayes classifiers is that they assume that the features you use are *conditionally independent*: knowledge of the outcome of one feature does not grant us knowledge of the outcome of any other feature. When dealing with text, this means that we’re not looking at entire sentences, but rather at individual words. So for our purposes, “this was a fun party” is the same as “this party was fun” and “party fun was this”.\n",
        "\n",
        "This is a pretty naive assumption (separate features are often correlated) — hence the name Naive Bayes Classifier. Yet, it turns out the algorithm often performs just as well than much more complex machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "92-uzgw6Zh1_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "58ce6543-f0c8-4034-f260-4aad93d7daed"
      },
      "source": [
        "# sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.feature_extraction import text\n",
        "stop = text.ENGLISH_STOP_WORDS\n",
        "\n",
        "# NLTK \n",
        "import nltk\n",
        "from nltk import FreqDist\n",
        "from nltk.classify import apply_features\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.classify import accuracy\n",
        "from nltk import NaiveBayesClassifier\n",
        "from nltk.metrics import precision as prec\n",
        "from nltk.metrics import recall as rec\n",
        "from nltk.metrics import f_measure as fmeas\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt') \n",
        "\n",
        "# pickle for saving\n",
        "import pickle\n",
        "\n",
        "# spacy for lemmatizing\n",
        "import spacy\n",
        "\n",
        "# VADER - installing using magic command `!pip install vaderSentiment` (command line script)\n",
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Gensim's preprocessor\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "# General data science\n",
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "import collections\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "%matplotlib inline\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.6/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vaderSentiment) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kLcYKobZh2G",
        "colab_type": "text"
      },
      "source": [
        "## Test using 20 Newsgroups\n",
        "\n",
        "The 20 newsgroups dataset consists of around 18000 newsgroups posts on 20 topics. It's helpfully split in two subsets: one for training (i.e. development), and one for testing (i.e. performance evaluation). \n",
        "\n",
        "We will use a Naive Bayes classifier to **predict the topics of the posts in our test set**, based on the **word frequencies** in the posts in our training set. \n",
        "\n",
        "First, let's get the data. The `.target_names` method yields the topics that the newsgroups have been classified in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOt10CYJZh2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = fetch_20newsgroups()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugSYmOUG_5OL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "cdd986aa-ff8a-47d7-a518-f217f5e497cc"
      },
      "source": [
        "data.target_names"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw_yEuIwZh2L",
        "colab_type": "text"
      },
      "source": [
        "Let's just get four of those to do our test with. We create a **training set** and a **test set**. The training set is, as the name implies, to train our classifier on. The test set we use to evaluate the performance of that classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3uzq1PbZh2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories = ['talk.religion.misc', 'soc.religion.christian',\n",
        "              'sci.space', 'comp.graphics']\n",
        "train = fetch_20newsgroups(subset='train', categories=categories)\n",
        "test = fetch_20newsgroups(subset='test', categories=categories)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53SVW8StAWuH",
        "colab_type": "text"
      },
      "source": [
        "What does the data look like?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ICNv8mJZh2P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5e4ecdae-05e1-4571-af95-e88490e57bd3"
      },
      "source": [
        "test.data[5]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"From: jsledd@ssdc.sas.upenn.edu (James Sledd)\\nSubject: Re: Dreams and out of body incidents\\nOrganization: Social Science Computing\\nLines: 6\\n\\nIn article <May.14.02.10.02.1993.25119@athos.rutgers.edu> alisonjw@spider.co.uk (Alison J Wyld) writes:\\n>From: alisonjw@spider.co.uk (Alison J Wyld)\\n>PS. Just to make it clear, I don't do ( and have never tried ) OOBEs.\\n>    I tend to think they are off limits for Christians.\\n\\nWHY?\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXyqHlD9Zh2S",
        "colab_type": "text"
      },
      "source": [
        "To convert the content of each string into a vector of numbers, we will use Scikit-learn's `TfidfVectorizer()` method again.\n",
        "\n",
        "We're using sklearn's `MultinomialNB` as our classifier. **Multinomial Naive Bayes** is a specialized version of Naive Bayes that is specifically designed for text documents. Whereas *Simple Naive Bayes* would model a document as the presence and absence of particular words, *Multinomial Naive Bayes* explicitly models all the word counts and adjusts the underlying calculations. For more on the difference between these classifiers, see:\n",
        "http://blog.datumbox.com/machine-learning-tutorial-the-naive-bayes-text-classifier/ \n",
        "\n",
        "Scikit-klearn allows us to create a **pipeline** using `make_pipeline()`, which attaches this vectorizer to a multinomial naive Bayes classifier (meaning we don't have to instantiate these methods separately)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoJH0bNhZh2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kd_-mpZZh2W",
        "colab_type": "text"
      },
      "source": [
        "### Fitting the data\n",
        "\n",
        "With this pipeline, we can apply the model to the training data, and then predict labels for the test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS5bcRveZh2X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train.data, train.target)\n",
        "labels = model.predict(test.data)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2kdy0wEZh2c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80a6ccab-f120-46a5-ad4f-2e66f6a6a368"
      },
      "source": [
        "labels[:5]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 0, 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WazqxP9Zh2f",
        "colab_type": "text"
      },
      "source": [
        "Now that we have predicted the labels for the test data, we can evaluate them to learn about the performance of the estimator. For example, here is the confusion matrix between the true and predicted labels for the test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "088ylqrUZh2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "3fd9662f-0f18-42ca-92a2-85d5abb8f8a9"
      },
      "source": [
        "mat = confusion_matrix(test.target, labels)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=train.target_names, yticklabels=train.target_names)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdkPbe78Zh2j",
        "colab_type": "text"
      },
      "source": [
        "Evidently, even this very simple classifier based on tf-idf scores can successfully separate posts about space from posts about computers. It gets confused, however, between talk about religion and talk about Christianity – an expected area of confusion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAZIndhPZh2k",
        "colab_type": "text"
      },
      "source": [
        "### Prediction\n",
        "With this classifier, we can now determine the category for any string, using the `predict()` method of this pipeline. Let's write a utility function that will return the prediction for a single string:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJWF5EoLZh2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_category(s, train=train, model=model):\n",
        "    pred = model.predict([s])\n",
        "    return train.target_names[pred[0]]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZzDrageZh2n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "64ed6721-0956-4ac7-fb8e-d186483b4ae0"
      },
      "source": [
        "predict_category('Scientists discover new moon around Saturn')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sci.space'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV-gmENZZh2r",
        "colab_type": "text"
      },
      "source": [
        "It works!\n",
        "\n",
        "**Remember:** this is nothing more than a simple probability model for the (weighted) frequency of each word in the string! Nevertheless, the result is striking. Even a very naive algorithm, when used carefully and trained on a large set of high-dimensional data, can be surprisingly effective."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfeqs_V-Zh2r",
        "colab_type": "text"
      },
      "source": [
        "## Classification on r/amitheasshole\n",
        "\n",
        "We will now use the same technique on a subreddit. We'll be using the subreddit r/amitheasshole: a subreddit in which members can vote whether an original poster [OP], in some social interaction, behaved \"assholeish\". "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDeidiecZOop",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "We'll start by cleaning up our data a bit. Let's load it up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdPlCnJbGIdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LaEjctJwtPnI",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"1OGjtSWvPKmDseWQuzWA2EfoX_41ohhGo\"})   \n",
        "downloaded.GetContentFile('amita-submissions.csv')"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cY6-yUcZOoq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3e4c873e-a118-44a6-eb52-612dfe7689f4"
      },
      "source": [
        "# load into df\n",
        "df = pd.read_csv(\"amita-submissions.csv\", lineterminator='\\n', encoding=\"utf8\")[:20000]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (7,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BobIKSa8Zh2t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b11d58ba-b1a1-4e8c-a998-275528a1a652"
      },
      "source": [
        "# clean up empty entries\n",
        "df = df.drop(['augmented_at', 'augmented_count', 'distinguish'], axis=1)\n",
        "df = df[~df['selftext'].isin(['[removed]', '[deleted]' ])].dropna(subset=['selftext'])\n",
        "len(df)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16267"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIgcztQ4Zh2w",
        "colab_type": "text"
      },
      "source": [
        "**Note:** if working with this entire dataset is still taking too long, consider using a slice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VamFANgBZh2x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "97725ccc-0aa1-4d9e-d816-eecec11a896b"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idint</th>\n",
              "      <th>idstr</th>\n",
              "      <th>created</th>\n",
              "      <th>self</th>\n",
              "      <th>nsfw</th>\n",
              "      <th>author</th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>selftext</th>\n",
              "      <th>score</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>textlen</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>flair_text</th>\n",
              "      <th>flair_css_class</th>\n",
              "      <th>selftext_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>87247149</td>\n",
              "      <td>t3_1fy0bx</td>\n",
              "      <td>1370724175</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>flignir</td>\n",
              "      <td>AItA: I like air conditioning and my coworkers...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I work in an office that requires me to wear a...</td>\n",
              "      <td>2</td>\n",
              "      <td>AmItheAsshole</td>\n",
              "      <td>1067</td>\n",
              "      <td>1</td>\n",
              "      <td>not the asshole</td>\n",
              "      <td>not</td>\n",
              "      <td>I work in an office that requires me to wear a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>118961390</td>\n",
              "      <td>t3_1ytr72</td>\n",
              "      <td>1393275159</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Irishman_reddit</td>\n",
              "      <td>[AITA] Construction worker here</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I have been on a parking structure project for...</td>\n",
              "      <td>63</td>\n",
              "      <td>AmItheAsshole</td>\n",
              "      <td>565</td>\n",
              "      <td>9</td>\n",
              "      <td>too close to call</td>\n",
              "      <td>NaN</td>\n",
              "      <td>I have been on a parking structure project for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>118969807</td>\n",
              "      <td>t3_1ytxov</td>\n",
              "      <td>1393278651</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Bobsmit</td>\n",
              "      <td>[AITA] I wrote an explanation in TIL and came ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Here is the post in question](http://www.redd...</td>\n",
              "      <td>51</td>\n",
              "      <td>AmItheAsshole</td>\n",
              "      <td>510</td>\n",
              "      <td>13</td>\n",
              "      <td>asshole</td>\n",
              "      <td>ass</td>\n",
              "      <td>Here is the post in question http www.reddit.c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>118975728</td>\n",
              "      <td>t3_1yu29c</td>\n",
              "      <td>1393281184</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>WoopAhhh</td>\n",
              "      <td>[AITA] Threw my parent's donuts away</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My parents are diabetic, morbidly obese, and a...</td>\n",
              "      <td>142</td>\n",
              "      <td>AmItheAsshole</td>\n",
              "      <td>735</td>\n",
              "      <td>27</td>\n",
              "      <td>asshole</td>\n",
              "      <td>ass</td>\n",
              "      <td>My parents are diabetic morbidly obese and add...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>118978034</td>\n",
              "      <td>t3_1yu41e</td>\n",
              "      <td>1393282238</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>ThisIsMeYoRightHere</td>\n",
              "      <td>[AITA] I Put My Empty Beer on a Bar Table</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Relevant Facts:\\n\\n1) It was a crowded bar, th...</td>\n",
              "      <td>46</td>\n",
              "      <td>AmItheAsshole</td>\n",
              "      <td>660</td>\n",
              "      <td>7</td>\n",
              "      <td>nothing happened</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Relevant Facts It was a crowded bar the table ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       idint  ...                                     selftext_clean\n",
              "0   87247149  ...  I work in an office that requires me to wear a...\n",
              "1  118961390  ...  I have been on a parking structure project for...\n",
              "2  118969807  ...  Here is the post in question http www.reddit.c...\n",
              "3  118975728  ...  My parents are diabetic morbidly obese and add...\n",
              "4  118978034  ...  Relevant Facts It was a crowded bar the table ...\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_tfxb_-Zh21",
        "colab_type": "text"
      },
      "source": [
        "We can clean up some of the text in our DataFrame using a function which we `apply()` to the selftext column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YEAgyjoZh21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "  # Normalize tabs and remove newlines\n",
        "  no_tabs = text.replace('\\t', ' ').replace('\\n', '');\n",
        "  # Remove all characters except A-Z and a dot.\n",
        "  alphas_only = re.sub(\"[^a-zA-Z\\.]\", \" \", no_tabs);\n",
        "  # Normalize spaces to 1\n",
        "  multi_spaces = re.sub(\" +\", \" \", alphas_only);\n",
        "  # Strip trailing and leading spaces\n",
        "  no_spaces = multi_spaces.strip();\n",
        "  return no_spaces\n",
        "\n",
        "df[\"selftext_clean\"] = df[\"selftext\"].apply(lambda x: clean_text(x))"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5KfKs5QZh25",
        "colab_type": "text"
      },
      "source": [
        "### A classifier for assholes?\n",
        "\n",
        "Now that we've seen how classification works, let's write a classifier for this subreddit. A typical use of this would be, for instance, to classify which particular subreddit a post belongs to. Or to classify posts that should be categorized as \"NSFW\".\n",
        "\n",
        "But you can also use classification to test out certain hypotheses: for instance, can we predict whether a post will be classified as \"ITA\" (*Is The Asshole*), given its textual features?\n",
        "\n",
        "Luckily, the members of r/amitheasshole have done some work for us by labeling the posts. We can use these labels to train our classifier. Let's have a look at the `flair_css_class` column in our DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ZUvOYdwvZh26",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "28423424-6ecf-4b43-ff2d-e41fdd9f2ec0"
      },
      "source": [
        "df['flair_css_class'].value_counts()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "not         8893\n",
              "ass         3352\n",
              "shitpost      55\n",
              "Name: flair_css_class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1dGxPvHZh2-",
        "colab_type": "text"
      },
      "source": [
        "Looks like the `flair_css_class` column contains lots of tags for asshole and non-asshole posts. Let's use this column for now. We'll remove anything that's *not* classified as `not` or `ass`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arX-cAJaZh2_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "883a7add-a6b2-4670-eff0-98918523bed5"
      },
      "source": [
        "df = df[~df['flair_css_class'].isin(['shitpost', '1' ])].dropna(subset=['flair_css_class'])\n",
        "len(df)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12245"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NobKEzQZh3D",
        "colab_type": "text"
      },
      "source": [
        "The next issue is that we have an unbalanced classification: \"Not the Asshole\" (`not`) posts occur over double as many times as \"Asshole\" (`ass`). We can choose to either **upsample** our \"Asshole\" category (by adding doubles) or **downsampling** our \"Not the A-hole\" category by removing entries. You ideally have to try both, as what works best differs from case to case, but let's downsample for now. \n",
        "\n",
        "First, we want our DataFrame sorted. Then, we create a boolean mask for the negative values, use `np.where` to get the indices of these rows, `drop` these indices, then drop one half of those indices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjH-L3b6Zh3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sorting the values\n",
        "df.sort_values('flair_css_class', inplace=True)\n",
        "\n",
        "# creating a mask for the condition\n",
        "mask = (df.flair_css_class == \"not\")\n",
        "\n",
        "# find out which indexes this condition refers to using np.where()\n",
        "idx, = np.where(mask)\n",
        "\n",
        "# divide by 2 and drop the indices\n",
        "df.drop(df.index[idx[:len(idx)//2]], inplace=True)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI78mD1GLhwR",
        "colab_type": "text"
      },
      "source": [
        "Let's see how many entries for our classes we have now.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rob-rhLRLeP-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c6f46c83-d069-433e-c866-df7d065c3a80"
      },
      "source": [
        "df['flair_css_class'].value_counts()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ass    3352\n",
              "not    2965\n",
              "Name: flair_css_class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TlscDpmZh3H",
        "colab_type": "text"
      },
      "source": [
        "Looks more balanced now!\n",
        "\n",
        "Next, let's work on our input features. We'll start by lemmatizing and POS-filtering our texts. We'll output strings for each post which we can then load into our vectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EV0FTpmZh3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "stop = set(stopwords.words('english') + ['’', '“', '”', 'nbsp', 'http', 'edit'])\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'VERB', 'ADJ', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    out = []\n",
        "    for text in texts:\n",
        "        doc = nlp(text) \n",
        "        stop_out = [token for token in doc if token not in stop]\n",
        "        out.append(' '.join([token.lemma_ for token in stop_out if token.pos_ in allowed_postags]))\n",
        "    return out"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csdh6GCDZh3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmas = lemmatization(df.selftext_clean)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c487Jhn-JXer",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "f4c4a5f6-c370-446f-928e-74afc56586f0"
      },
      "source": [
        "lemmas[:10]"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['s again sometimes trouble judge situation so sub really helpful roommate ask credit card car pay online come back in talk while conversation turn weather tell hear go snow today most tomorrow reply tell m wrong s just go flurry tell s just hear reply again tell s grandpa say wouldn wrong watch news so know hell s talk tell s defensive tell fuck room think need different roommate asshole',\n",
              " 'so background m university program give strong background exercise exercise prescription movement cue other gym relate stuff also haven regularly exercise year ve been try fit again cardio intramural soccer hit gym when come gym cognitively know how correct movement other skill personal trainer may can t most exercise beginn level importantly personal trainer however so tonight work friend mine see study start chat say go gym ask go roughly same size ve never gym buddy before hadn t intend go gym tonight so pair short runner polo shirt wear job athletic therapy clinic get school gym warm start trade set squat buddy weightlift lot longer m fall behind set m weak paranoid form do set correct form vice versa point get drop intensity focus specific muscle activation cue would athlete fix movement eventually move own plan join workout few movement don mobility strength so spend decent chunk time stand around watch involve correct movement polo shirt otherwise nearly dead gym night where go may expect staff walk give weird look attribute time shirt eventually try do pullup maximum rep weak then go water buddy do full set staff member recognize student deptartment come ask training friend say tell s obvious m do again respectfully disagree train buddy staff member say will give warning would well just get hire do table training else s gym steal business realize circumstance go end win conversation so take warning more pullup buddy leave shock happen have accuse unauthorized personal training indirectly steal somebodys job didn want buddy squat wrong also strong enough workout plan feel m asshole wrong asshole here steal somebodys potential client wasn do intention training guy wasn get pay buddy pay training anyways say work gym see do do probably would have question judge reddit',\n",
              " 'while ago ride bike street when come way intersection right woman car pass front stop sign slow read cyclist always right way car proceed cross car stop driver then throw hand gesture suppose let go first correct asshole where s flaw logic m matter make mistake want know should differently future especially action could jeopardize safety other thank',\n",
              " 'happen several year ago drive school there almost year decide sell car plate stay person car sell car don notify just don renew registration first car d ever sell young nervous sell car guy so sign part transfer registration paperwork give have sign also forget take plate several hour leave realize begin worry happen trouble didn think could figure d just hope good next day roommate come say sell car yesterday respond then tell park back street block away college campus strict parking limit crap m totally go fine go car see ticket decide take plate mind re right just fail take when sell car forward week get few call didn t answer sleep go voicemail first one say right take plate call back d go no further second one say literally bad kind person wasn t mad hope kill very violent painful way third final call local police department end ever come police officer call never hear again probably should at least tell when take other aita',\n",
              " 'permabanne poster start use reddit when would make occasional shitpost here there first too bad however get bad bad time would start copy other people post slide n word paragraph eventually take too much effort lot people would catch just start post blatant racism would go various gaming subreddit find top comment reply such thing hang black think negro disgusting man beast get point couldn t think post racism eventually hater catch wind same person make racist comment flat ban entire ip opinion complete overkill now only thing can make post hope dozen so people see racist post here feel admin could just accommodate shitposte addiction just continue ban seperate account instead entire ip range',\n",
              " 'event tonight need black button shirt buy use app call huge discount seller never ship luckily get refund app solve problem need tonight store m go day return policy item so m probably go go mall buy leave tag wear tonight event wash return store tomorrow unethical just curious',\n",
              " 'friend class will call talk dungeon dragon campaign play few other friend school then start complain how other friend l bad game how interrupt dungeon master time later on see mention feel right know say come few day later basically tell piss tell l didn apologize weren go friend anymore didn feel wrong so tell wasn t so wasn go apologize respond call childish asshole claim only tell ruin friendship think m asshole tell l say',\n",
              " 'think share cloth gross',\n",
              " 'm even sure why re mad english class group discuss book first girl group always complain walk class hate english class steel coffee cup ask s cup s glass need where go proceed mock sometime later re discuss book wasn t pay attention so interrupt other girl talk ask say s visibly confused continue talk clarify ask even listen then girl first mention just say re asshole why s so annoying stunned now m wonder s just complainer asshole get interrupting rude complete accident suppose discuss group shock when get criticize do just edit complain girl seem problem interruption so much problem falsely disagree misheard other girl',\n",
              " 's really maid let call simplicity mom pay come help clean house whatnot other day walk downstairs mom talk tell how maid good friend so jokingly say mom only like pay obviously insult mom always joke maid today clean mom bring how hurt maid feeling quickly apologize clear air didn mean harm m just really confused didn t even joke only mom asshole never be dumbfound before mom certainly didn take wrong way']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OZ4XJ8pZh3Q",
        "colab_type": "text"
      },
      "source": [
        "Lemmatizing takes a long time, so we don't want to do it twice. We'll save the lemmatized list in a pickle, in case we need it later. Note that you can download files from your Colab workspace by clicking the folder icon to the left and clicking \"download\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkNfRwa6Zh3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pickling\n",
        "with open(\"lemmas.lem\", \"wb\") as cp: \n",
        "    pickle.dump(lemmas, cp)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhX9w8AuZh3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unpickling\n",
        "with open(\"lemmas.lem\", \"rb\") as cp: \n",
        "    lemmas = pickle.load(cp)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-O-DEjUZh3V",
        "colab_type": "text"
      },
      "source": [
        "### Commence training\n",
        "\n",
        "Now for the classfier! We'll first create our training and test set, using the lemmas as `X` and `flair_css_class` as `y`. So we're predicting `y` given `X`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JdK3MbCZh3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = lemmas\n",
        "y = df['flair_css_class']"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8zRQxjnZh3Z",
        "colab_type": "text"
      },
      "source": [
        "Next, we split our data into training and test sets again. We can easily do this using scikit-learn's `train_test_split()` method. The method takes a parameter denoting the size of the test set (20% of the total set, in this case)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOG6EFYxZh3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9R_1wQkZh3e",
        "colab_type": "text"
      },
      "source": [
        "Why are we splitting into training and testing sets before vectorizing?\n",
        "\n",
        "If we vectorize *before* we train/test split, our doc-term matrix would contain every single feature (word) in the test and training sets. What we want is to simulate the real world, where our classifier needs to encounters words it has not seen before. This allows us to evaluate it better.\n",
        "\n",
        "So here's what we're doing: \n",
        "\n",
        "- We create a `TfidfVectorizer` instance\n",
        "- `vect.fit.transform(X_train)` learns the t-fidf vocabulary of the training data, and uses the fitted vocabulary to build a document-term matrix from the training data;\n",
        "- `vect.transform(X_test)` uses the fitted vocabulary to build a document-term matrix from the testing data (and ignores tokens it hasn't seen before)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkpEXpiMZh3f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "91803c5a-8778-49f1-af05-e10732dc88e4"
      },
      "source": [
        "vect = TfidfVectorizer(max_df=1.0, max_features=None, min_df=1) # we can add ngram_range=(1, 2) to include N-grams\n",
        "\n",
        "# learn training data vocabulary, then use it to create a document-term matrix\n",
        "X_train_dtm = vect.fit_transform(X_train)\n",
        "\n",
        "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
        "X_test_dtm = vect.transform(X_test)\n",
        "X_test_dtm"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1264x15934 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 115605 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxGDyW1hZh3i",
        "colab_type": "text"
      },
      "source": [
        "Time to create the classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWtVY_FRZh3i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6dad72a6-55a4-4cfe-da51-214bd712e61c"
      },
      "source": [
        "nb = MultinomialNB()\n",
        "%time nb.fit(X_train_dtm, y_train)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 22.1 ms, sys: 2 µs, total: 22.1 ms\n",
            "Wall time: 22.7 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txTEsCUDZh3l",
        "colab_type": "text"
      },
      "source": [
        "That was quick! Let's see what it yields."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SSQmwNFsZh3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40c5fa76-dd60-4a3b-e9a4-9081e42fa33f"
      },
      "source": [
        "# Make class predictions for X_test_dtm\n",
        "y_pred_class = nb.predict(X_test_dtm)\n",
        "\n",
        "# Calculate accuracy of class predictions\n",
        "from sklearn import metrics\n",
        "metrics.accuracy_score(y_test, y_pred_class)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.553006329113924"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "WPxFORXUZh3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "ac91ddbb-ee76-43e6-dd12-ec2f65067ae1"
      },
      "source": [
        "categories = ['ass', 'not']\n",
        "mat = confusion_matrix(y_test, y_pred_class)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=categories, yticklabels=categories)\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label')"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(91.68, 0.5, 'predicted label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZp_FeIBZh3r",
        "colab_type": "text"
      },
      "source": [
        "Well, that doesn't work very well!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jMbvaKPZh3s",
        "colab_type": "text"
      },
      "source": [
        "### OPTIONAL: Classification using logistic regression\n",
        "\n",
        "Our predictions are not particularly accurate. This is no surprise, as it would be quite a feat to predict this class based on word usage alone! If you'd want to pursue this hypothesis further, you could try to take more features for X into account. \n",
        "\n",
        "Just for fun, let's try comparing this result to **logistic regression**, which is also often used for classification problems. Logistic regression tries to find the optimal decision boundary that best separates classes.\n",
        "\n",
        "The difference between Naive Bayes and Logistic regression is that the first is a generative model, and the second a discriminative model. What does this mean?\n",
        "- **Generative model**: Naive Bayes models the joint distribution of the feature X and target y, and then *predicts* the posterior probability given as P(y|X)\n",
        "- **Discriminative model**: Logistic regression *directly models* the posterior probability of P(y|X) by learning the input to output mapping and minimizing the error.\n",
        "\n",
        "Unlike Naive Bayes, logistic regression typically works reasonably well even when some of the features (in our case, words) are correlated. This is why it can be a good idea to try both when dealing with texts (because certain words *do* tend to appear in each other's vicinity!)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZv1bpRaZh3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiate a logistic regression model\n",
        "logreg = LogisticRegression()"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se7nezO_Zh3w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "04e052c8-ca50-4f17-9250-dd6da2a19ea8"
      },
      "source": [
        "# train the model using X_train_dtm\n",
        "%time logreg.fit(X_train_dtm, y_train)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 391 ms, sys: 237 ms, total: 629 ms\n",
            "Wall time: 335 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrD54i3PZh3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make class predictions for X_test_dtm\n",
        "y_pred_class = logreg.predict(X_test_dtm)"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HA25D0fZh31",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "57eccf11-4a0e-435a-fb77-3bdce62b5e85"
      },
      "source": [
        "# calculate predicted probabilities for X_test_dtm\n",
        "y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
        "y_pred_prob"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.43212744, 0.50684742, 0.37648649, ..., 0.65012314, 0.51285732,\n",
              "       0.54861956])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jKqAj5XpZh33",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f5636582-93dc-4a25-c864-0adb6bf4af57"
      },
      "source": [
        "# calculate accuracy\n",
        "metrics.accuracy_score(y_test, y_pred_class)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5411392405063291"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-xenYmXZh36",
        "colab_type": "text"
      },
      "source": [
        "Still no good – but you get the idea."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tAYGMaxZh37",
        "colab_type": "text"
      },
      "source": [
        "### Improving the model\n",
        "\n",
        "If you'd want to improve upon this model, you could try to extract other features from the text (for instance, based on the presence of certain words, sentence length, etc.). You could also start looking into other features from the metadata (e.g. the score it received) to improve the prediction – though this is beyond the scope of this notebook.\n",
        "\n",
        "What you need to know is that this process is called **feature engineering**: taking whatever information you have about your problem and turning it into numbers that you can use to build your feature matrix.\n",
        "\n",
        "Plugging other features into a classifier could potentially make it more accurate. For now, we can say that we cannot really tell the label based only on the words that people use in their posts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86yH3K8gZh37",
        "colab_type": "text"
      },
      "source": [
        "### Finding the most distinctive terms\n",
        "\n",
        "Before we move on, let's explore why we would want an accurate model in the first place! For one, this would allow us to calculate the approximate \"assholishness\" of each token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3e03LYnZh38",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a86ecb3-17bb-4100-b850-83b4ec70f20f"
      },
      "source": [
        "# store the vocabulary of X_train\n",
        "X_train_tokens = vect.get_feature_names()\n",
        "len(X_train_tokens)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15934"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP6sp8YbZh4B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6fd3b28c-c45d-478f-cbdd-f98e52ced045"
      },
      "source": [
        "# examine some tokens\n",
        "print(X_train_tokens[100:150])"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['account', 'accountability', 'accountable', 'accountant', 'accounting', 'accredit', 'accross', 'accrue', 'accumulate', 'accumulation', 'accurate', 'accurately', 'accusation', 'accusatory', 'accuse', 'accused', 'accustom', 'accustomed', 'ace', 'acedemy', 'ache', 'achievable', 'achieve', 'achievement', 'achievment', 'achondroplastic', 'achss', 'acid', 'acknowledge', 'acknowledgement', 'acknowledgment', 'acnl', 'acount', 'acoustic', 'acquaint', 'acquaintance', 'acquainted', 'acquantence', 'acquire', 'acquisition', 'acre', 'acrimonious', 'acrobatic', 'acronym', 'across', 'acrylic', 'act', 'acting', 'action', 'activally']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0oP92h-QAy9",
        "colab_type": "text"
      },
      "source": [
        "Naive Bayes counts the number of times each token appears in each class. We can access the array of that count by running the `.feature_count_` method.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJrm5uoPZh4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "387fb9b9-f9e5-4247-f314-9fae6e89b0bb"
      },
      "source": [
        "# note that the trailing underscore often acts to avoid naming errors\n",
        "nb.feature_count_ "
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.08217246, 0.06929399, 0.29307101, ..., 0.17275316, 0.56178693,\n",
              "        0.20103568],\n",
              "       [0.        , 0.        , 0.        , ..., 0.22001616, 0.20061056,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXTq54cCQlQO",
        "colab_type": "text"
      },
      "source": [
        "What are we seeing here? The rows represent our classes (asshole / not an asshole), the columns represent our tokens (our total vocabulary).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY5OhscsZh4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c774c4d7-df95-4cb4-b3a6-66f3e866005a"
      },
      "source": [
        "# rows represent classes, columns represent tokens\n",
        "nb.feature_count_.shape"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 15934)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foPzSHKOZh4K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "23851411-7a66-42a0-8da7-9ba09871ba5e"
      },
      "source": [
        "# number of times each token appears across all ASS posts\n",
        "ass_token_count = nb.feature_count_[0, :]\n",
        "ass_token_count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.08217246, 0.06929399, 0.29307101, ..., 0.17275316, 0.56178693,\n",
              "       0.20103568])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx9YFtPNZh4M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "365de26e-22ba-46d6-a875-29741bb2c8cf"
      },
      "source": [
        "# number of times each token appears across all NOT posts\n",
        "not_token_count = nb.feature_count_[1, :]\n",
        "not_token_count"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , ..., 0.22001616, 0.20061056,\n",
              "       0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fisNTo6RROc1",
        "colab_type": "text"
      },
      "source": [
        "We can now create a DataFrame of tokens with their separate ASS and NOT counts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_HhyTR6rZh4Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "81a2fca0-edbd-4efc-f4cd-cac18c0c7fab"
      },
      "source": [
        "tokens = pd.DataFrame({'token':X_train_tokens, 'ass':ass_token_count, 'not':not_token_count}).set_index('token')\n",
        "tokens[110:120] # just a random slice"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ass</th>\n",
              "      <th>not</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>token</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>accurate</th>\n",
              "      <td>0.454172</td>\n",
              "      <td>0.141095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accurately</th>\n",
              "      <td>0.186609</td>\n",
              "      <td>0.217066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accusation</th>\n",
              "      <td>0.735965</td>\n",
              "      <td>0.519482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accusatory</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.421599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuse</th>\n",
              "      <td>4.242511</td>\n",
              "      <td>5.024768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accused</th>\n",
              "      <td>0.090578</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accustom</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.152566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accustomed</th>\n",
              "      <td>0.085921</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ace</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.087371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>acedemy</th>\n",
              "      <td>0.112799</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 ass       not\n",
              "token                         \n",
              "accurate    0.454172  0.141095\n",
              "accurately  0.186609  0.217066\n",
              "accusation  0.735965  0.519482\n",
              "accusatory  0.000000  0.421599\n",
              "accuse      4.242511  5.024768\n",
              "accused     0.090578  0.000000\n",
              "accustom    0.000000  0.152566\n",
              "accustomed  0.085921  0.000000\n",
              "ace         0.000000  0.087371\n",
              "acedemy     0.112799  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwi7-mcsRl6i",
        "colab_type": "text"
      },
      "source": [
        "Using `.class_count_`, we can count the number of observations in each class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "5yTWTl_qZh4V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a64632e-e844-456d-e571-f87e3842f6a7"
      },
      "source": [
        "# Naive Bayes counts the number of observations in each class\n",
        "nb.class_count_"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2698., 2355.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ClI4U7QVZh4Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "71aaf12a-0d9a-4d92-d2af-9e4428bc4765"
      },
      "source": [
        "# add 1 to 'ass' and 'not' counts to avoid dividing by 0\n",
        "tokens['ass'] = tokens['ass'] + 1\n",
        "tokens['not'] = tokens['not'] + 1\n",
        "tokens.sample(5, random_state=6)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ass</th>\n",
              "      <th>not</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>token</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>undergo</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.332385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meth</th>\n",
              "      <td>1.034969</td>\n",
              "      <td>2.133004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>physique</th>\n",
              "      <td>1.412383</td>\n",
              "      <td>1.174831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cheeseburger</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.219543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>baptism</th>\n",
              "      <td>1.116484</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   ass       not\n",
              "token                           \n",
              "undergo       1.000000  1.332385\n",
              "meth          1.034969  2.133004\n",
              "physique      1.412383  1.174831\n",
              "cheeseburger  1.000000  1.219543\n",
              "baptism       1.116484  1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU5nSXh3Zh4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "be013938-d35e-495b-dead-f6dc4b3b421a"
      },
      "source": [
        "# convert the 'ass' and 'not' counts into frequencies\n",
        "tokens['ass'] = tokens['ass'] / nb.class_count_[0]\n",
        "tokens['not'] = tokens['not'] / nb.class_count_[1]\n",
        "tokens.sample(5, random_state=6)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ass</th>\n",
              "      <th>not</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>token</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>undergo</th>\n",
              "      <td>0.000371</td>\n",
              "      <td>0.000566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meth</th>\n",
              "      <td>0.000384</td>\n",
              "      <td>0.000906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>physique</th>\n",
              "      <td>0.000523</td>\n",
              "      <td>0.000499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cheeseburger</th>\n",
              "      <td>0.000371</td>\n",
              "      <td>0.000518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>baptism</th>\n",
              "      <td>0.000414</td>\n",
              "      <td>0.000425</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   ass       not\n",
              "token                           \n",
              "undergo       0.000371  0.000566\n",
              "meth          0.000384  0.000906\n",
              "physique      0.000523  0.000499\n",
              "cheeseburger  0.000371  0.000518\n",
              "baptism       0.000414  0.000425"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIVy9xmUZh4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "684d423a-d052-4896-825d-9f9245922f0d"
      },
      "source": [
        "# calculate the ratio of ass-to-not for each token\n",
        "tokens['ass_ratio'] = tokens['ass'] / tokens['not']\n",
        "tokens.sample(5, random_state=6)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ass</th>\n",
              "      <th>not</th>\n",
              "      <th>ass_ratio</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>token</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>undergo</th>\n",
              "      <td>0.000371</td>\n",
              "      <td>0.000566</td>\n",
              "      <td>0.655118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meth</th>\n",
              "      <td>0.000384</td>\n",
              "      <td>0.000906</td>\n",
              "      <td>0.423531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>physique</th>\n",
              "      <td>0.000523</td>\n",
              "      <td>0.000499</td>\n",
              "      <td>1.049364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cheeseburger</th>\n",
              "      <td>0.000371</td>\n",
              "      <td>0.000518</td>\n",
              "      <td>0.715734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>baptism</th>\n",
              "      <td>0.000414</td>\n",
              "      <td>0.000425</td>\n",
              "      <td>0.974544</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   ass       not  ass_ratio\n",
              "token                                      \n",
              "undergo       0.000371  0.000566   0.655118\n",
              "meth          0.000384  0.000906   0.423531\n",
              "physique      0.000523  0.000499   1.049364\n",
              "cheeseburger  0.000371  0.000518   0.715734\n",
              "baptism       0.000414  0.000425   0.974544"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH8mWcAnR9sf",
        "colab_type": "text"
      },
      "source": [
        "Finally, we can examine the DataFrame sorted by ass_ratio. These are the words, according to our classifier, that are the most typical of \"assholeish\" posts. A well-working classifier would yield interesting info here on how telling each word is for being considered an asshole by the community. But then again, creating such a classifier is not a trivial matter.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO7FYCGHZh4h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "7afb0063-6066-4a80-a671-a66dfe9faea1"
      },
      "source": [
        "# note: use sort() instead of sort_values() for pandas 0.16.2 and earlier\n",
        "tokens.sort_values('ass_ratio', ascending=False)[:10]"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ass</th>\n",
              "      <th>not</th>\n",
              "      <th>ass_ratio</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>token</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>tree</th>\n",
              "      <td>0.001823</td>\n",
              "      <td>0.000669</td>\n",
              "      <td>2.724631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>explanatory</th>\n",
              "      <td>0.001142</td>\n",
              "      <td>0.000425</td>\n",
              "      <td>2.690329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>merge</th>\n",
              "      <td>0.001093</td>\n",
              "      <td>0.000425</td>\n",
              "      <td>2.574841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cent</th>\n",
              "      <td>0.001177</td>\n",
              "      <td>0.000465</td>\n",
              "      <td>2.530000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lawn</th>\n",
              "      <td>0.001720</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>2.416422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>overweight</th>\n",
              "      <td>0.001390</td>\n",
              "      <td>0.000583</td>\n",
              "      <td>2.383172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>microwave</th>\n",
              "      <td>0.001036</td>\n",
              "      <td>0.000446</td>\n",
              "      <td>2.322403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>drill</th>\n",
              "      <td>0.001137</td>\n",
              "      <td>0.000491</td>\n",
              "      <td>2.316760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>porn</th>\n",
              "      <td>0.001629</td>\n",
              "      <td>0.000705</td>\n",
              "      <td>2.311076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sin</th>\n",
              "      <td>0.001044</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>2.255120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  ass       not  ass_ratio\n",
              "token                                     \n",
              "tree         0.001823  0.000669   2.724631\n",
              "explanatory  0.001142  0.000425   2.690329\n",
              "merge        0.001093  0.000425   2.574841\n",
              "cent         0.001177  0.000465   2.530000\n",
              "lawn         0.001720  0.000712   2.416422\n",
              "overweight   0.001390  0.000583   2.383172\n",
              "microwave    0.001036  0.000446   2.322403\n",
              "drill        0.001137  0.000491   2.316760\n",
              "porn         0.001629  0.000705   2.311076\n",
              "sin          0.001044  0.000463   2.255120"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFAf18XCZh4j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de807ab5-c1a6-45a7-f53a-16f8ac4cab4e"
      },
      "source": [
        "# look up the not_ratio for a given token\n",
        "tokens.loc['me', 'ass_ratio']"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8006683382302092"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiQuWUN9Zh4l",
        "colab_type": "text"
      },
      "source": [
        "Looks like the word 'me' occurs 3 as often for people who are classified as assholes (according to our very imprecise classifier at least). With a precise classifier, this would be a very interesting result!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH_tIIPyZh4m",
        "colab_type": "text"
      },
      "source": [
        "### Training for more classes\n",
        "\n",
        "We've trained for 2 classes now (asshole and non-asshole), but the posts in this subreddit (as well as many others) actually have more labels, called **flair**. We can find them here under the `flair_text` category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "zlfcXlTSZh4m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "370c4b96-e499-4a4b-9fb2-3e91f49d5472"
      },
      "source": [
        "df.flair_text.unique()[:100]"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Everyone Sucks', 'asshole', 'Asshole', 'Tactless!',\n",
              "       ' UnanimASSly the Asshole', 'Lesser Asshole', 'kinda',\n",
              "       ' The pizza is the asshole', 'teenager', 'Asshole kinda',\n",
              "       'assho-ho-ho', 'MetaAsshole', 'assholish', 'dingus', '8 assholes!',\n",
              "       'asshole (Kind of)', 'shallow', 'everyone sucks',\n",
              "       'obvious asshole', 'asshole/not a-hole', 'NTA / YTA', 'kind of',\n",
              "       'asshole (a bit)', 'total asshole', 'All assholes',\n",
              "       'asshole (Kinda)', 'asshole, kinda', 'asshole (tiny bit)',\n",
              "       'Both are Assholes', 'asshole, maybe?', 'Huge asshole',\n",
              "       'communicate', 'Troll', 'slightly', 'Shitpost', '10% asshole',\n",
              "       '20% asshole', 'OP is an asshole', 'de minimis assholery',\n",
              "       'tentative', 'Nobody cares :(', 'asshole, say hi',\n",
              "       'asshole (or young)', 'silent asshole', '(Accidental) Asshole',\n",
              "       'meta-asshole', 'Mild Asshole', 'huge asshole', 'colossal asshole',\n",
              "       '1/3 asshole', 'Um...What?', 'low key', '50/50', 'Meta',\n",
              "       'potential asshole', 'DM;HS asshole', 'Trolling', 'a bit',\n",
              "       'Advicehole', 'asshole kinda', 'half-asshole', 'justified asshole',\n",
              "       'Jared from Subway', 'mega-asshole', 'asshole (x3)',\n",
              "       'asshole and thief', 'Asshole (maybe justified?)', 'teenagers',\n",
              "       'beautiful asshole', 'selfish', 'retarded', 'frocket',\n",
              "       'Asshole-ish', 'asshole-y', 'asshole in theory', 'half asshole',\n",
              "       'asshole - kinda', 'asshole ...i guess', 'petty as fuck',\n",
              "       'slight asshole', 'arsehole', 'a little bit', 'Shit Post', 'wow.',\n",
              "       'minor asshole', 'criminal', 'family is asshole', 'dysfunction',\n",
              "       'suspect', 'just a little', 'Asshole (justified)', 'wall of text',\n",
              "       'asshole for posting', 'troll', 'Slightly the Asshole',\n",
              "       'Self-Inflicted but NTA', 'asshole & victim', 'no lollygag',\n",
              "       'tactless', 'no one cares'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2Qt_PAJZh4p",
        "colab_type": "text"
      },
      "source": [
        "Quite a lot of categories, turns out. Let's see what the most-frequent categories are, as well as their counts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Bx1jHEb1Zh4p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "0ea1fdbf-3648-4f58-828d-e8b3ebf1330e"
      },
      "source": [
        "df['flair_text'].value_counts()"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "not the a-hole        1738\n",
              "asshole               1729\n",
              "Asshole               1151\n",
              "Not the A-hole         761\n",
              "not the asshole        388\n",
              "                      ... \n",
              "OP trolling              1\n",
              "wow.                     1\n",
              "assholish                1\n",
              "of course not            1\n",
              "potential homocide       1\n",
              "Name: flair_text, Length: 276, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD3Dlhs6Zh4s",
        "colab_type": "text"
      },
      "source": [
        "There are a bunch of categories which we could concatenate in order to work with more data. This might make our classifier more accurate! For now, let's move on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Osp8M8qTZh4t",
        "colab_type": "text"
      },
      "source": [
        "## Automated sentiment analysis using NLTK VADER\n",
        "\n",
        "The second half of this notebook is about sentiment analysis (sometimes known as \"opinion mining\"). The most common use of sentiment analysis is to classify a text into a class (called \"sentiment classification\"). We'll get to that further on. First, let's see how sentiment analysis itself works.\n",
        "\n",
        "The simplest option is to use pre-built libraries for sentiment analysis. TextBlob and NLTK VADER are two examples of such libraties. VADER (Valence Aware Dictionary and sEntiment Reasoner) is specifically built for social media texts, and takes multiple text features into account, such as:\n",
        "\n",
        "- **Punctuation** (e.g. an exclamation mark \"!\" increases the magnitude of intensity)\n",
        "- **Capitalization** (e.g. \"The food here is GREAT\" is more intense than \"The food here is great\")\n",
        "- **Degree modifiers** (e.g. \"The service here is extremely good\" is more intense than \"The service here is good\")\n",
        "- **Conjunctions** signal a shift in sentiment polarity, with the sentiment of the text following the conjunction being dominant (e.g. “The food here is great, but the service is horrible”)\n",
        "- **Preceding Tri-grams** of a sentiment-laden lexical feature catch 90% of cases where negation flips the polarity of the text (e.g. \"The food here isn’t really all that great”)\n",
        "- **Emoji, emoticons & slang** are parsed very well by VADER."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1tFJ5caZh4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiate Class\n",
        "analyser = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CQ9bOWtZh4x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3c57983-a936-4545-db1a-94274244c438"
      },
      "source": [
        "# a small test\n",
        "analyser.polarity_scores(\"\"\"This is really dumb. I don't want to use this stupid \n",
        "                          program.\"\"\")"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': -0.8323, 'neg': 0.495, 'neu': 0.505, 'pos': 0.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFW3jV0qZh41",
        "colab_type": "text"
      },
      "source": [
        "VADER spits out several metrics we can use. The **Positive**, **Negative** and **Neutral** scores represent the proportion of text that falls in these categories. This means our sentence was rated as 35% Positive, 50% Neutral and 15% Negative. All these add up to 1.\n",
        "\n",
        "The **Compound** score is a metric that calculates the sum of all the lexicon ratings which have been normalized between -1 (most extreme negative) and +1 (most extreme positive). The compound score turns out to be 0.61: a pretty positive sentiment overall. Let's use that score for now (but be aware that you can use these `neg`, `neu` and `pos` scores to your advantage to train a more precise classifier!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws2-J4lsZh49",
        "colab_type": "text"
      },
      "source": [
        "Now let's write a function that takes a text in, and spits out one of 3 tags based on the compound score, as well as that compound score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ircdPv5AZh4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentiment_analyzer_scores(text):\n",
        "    sentiment_dict = analyser.polarity_scores(text)\n",
        "    # decide sentiment as positive, negative and neutral \n",
        "    if sentiment_dict['compound'] >= 0.01 : \n",
        "        tag = \"pos\"\n",
        "    elif sentiment_dict['compound'] <= - 0.01 : \n",
        "        tag = \"neg\"\n",
        "    else : \n",
        "        tag = \"neut\" \n",
        "    return [tag, sentiment_dict['compound']]"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiJQ_hLtZh5A",
        "colab_type": "text"
      },
      "source": [
        "Let's append the output to 2 new columns in our dataframe. `.apply()` allows us to apply a function along an axis of the DataFrame. Also note the use of `zip()` here, allowing us to map the 2 returned values of our function to the tuple of variables we assign them to. Finally, note the `*` to unpack these containers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGuQNv2iZh5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"sent\"], df[\"sent_compound\"] = zip(*df.selftext_clean.apply(sentiment_analyzer_scores))"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HzQ4EE_Zh5E",
        "colab_type": "text"
      },
      "source": [
        "Let's have a look:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "7Djl4vZQZh5E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c2616c2c-691a-492c-c185-eecf83fca32c"
      },
      "source": [
        "df.sent.value_counts()"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pos     3404\n",
              "neg     2860\n",
              "neut      53\n",
              "Name: sent, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jiBbH9XDZh5H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "85185b72-09a8-4524-a120-c3bebdf44bf7"
      },
      "source": [
        "df.hist(column=\"sent_compound\",bins=50)"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f9cb6a477b8>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImtMT8OtZh5K",
        "colab_type": "text"
      },
      "source": [
        "Let's see if these scores make sense. We'll print out the comment with the highest score (note: we could also use `.idxmax()` to find the comment with the highest score). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "svUJ4frjZh5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "82f981a4-5968-4217-b736-aad641bc4242"
      },
      "source": [
        "min_id = df.sent_compound.idxmin()\n",
        "df.selftext_clean[min_id]"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Buckle up folks because this is a long one. So about and a half years ago I reconnected with a girl I met online from canada that really seemed to click with me we shared alot of personal interests links etc. She was in this on off thing with another guy and living with an abusive father. She sends me a nude which causes the on off guy to flip out on me over Skype and I not wanting drama backed off for awhile but something about her hooked me like a drug. We start talking again and she says she wants to be with me and builds up the idea of a dream future. I m into it naturally but she seems really avoidant of making our status known to anyone which is fine shes got that weird ex right So I message a mutual friend and he blows up and starts a shitstorm of drama because she was evidently sexting him the ex and making plans with me. I have alot of drama in the place I m living at the time and see red flags so I deuce and end up in another relationship that I rapidly lose interest in but hang around because it s better than where I was before I am the asshole for that I know Jump forward months and she starts messaging me on Skype again and we reconnect as friends and I tell her I still think about her and flirt a bit a week or two later she sends a picture of her wet panties to my Skype while I m at work and current gf sees it at home and almost kicks me out making me homeless across the country from family so once again seeing a red flag I block her on everything months later current gf cheats on me when I play fallout after it comes out for days so I say screw it and deuce. Being in a bad place mentally and stuck moving in with parents again because my car died in a flood and I didnt have much money i cant stop thinking about Canada girl so i unblock and message her shes moved out of her dads broken things off with the ex more completely and now has an american trucker friend paying for her apartment while she is slowly slipping into depression from abusive father and ex he had been visiting her a few times at this point we hit it off again and trauma bound over childhood stuff toxic abusive mother and constant fighting as i grew up with step dad and one day she just vanishes for hours and I panic because shes had several prior suicide attempts. I call numerous people trying to figure out if shes okay including a guy who she hung out with irl sometimes he flips out on me and tries to tell me to go find an american girl so that sets off a weird flag... she calls me a short time later with a black eye and mad I contacted her friend up there I somehow ignored alot of red flags Suddenly she drops a bomb on me her dad showed up and hit her accidentally because she wouldn t hug him and she also breaks down and informs me of just how abusive he was when she lived with him. In the following month she spirals out hardcore trucker friend lost job she isnt working food runs out shes starving slowly to death suddenly starts acting really strange and informs me she ordered helium to off herself. I call a crisis team immediately because I ve fallen hard at this point and I ve lost several friends to suicide so its terrifying to just let someone go through that cop and psych lady show up ask questions she convinces things are fine and they leave. She panics after because she self medicated for epilepsy with weed and didnt want to get in trouble but she also cancels the helium order.At this point she starts disappearing on me again but I dont give up because I m terrified she ll off herself. Turns out shes talking to abusive ex again so I in my infinite wisdom somehow get roped into a way relationship for the sake of getting her away from stalker father and not ending up homeless or starving to death. Trucker guy also has job again at this point and wants to help too hes her friend of years who has always been hung up on her but she refuses to date because shes not into him SO the first months of the year shit saga begin... I fly up the other drive up a week later I help her get her passport renewed clean up her apartment which is a disgusting wreck she was letting her dog shit on the balcony and it was like inches thick but I was in the army and a plumber at one point so fuck it shes been through some fucked up shit I ll clean the place nbd she meanwhile fucks me like crazy and ignored her ex and tells me she just roped him in to help get this all done hes already been a sleezebag I moved in with him shortly before going up to Canada and his place was a shithole too and I guess I have a bleeding heart and shed drop him after. So first we drive all the way to trucker guys hometown with ex guy trying to sexualize her and grope her every chance he got despite her trauma and her not initiating and obviously being uncomfortable and telling him to stop.After a weird argument there with her being pissed with everyone but me me her and ex continue to his place against everything she had told me before basically I end up having or threesomes minus the fact the guy gives a weird vibe her and ex start having arguments that spiral into insanity and end with her locking herself in the bathroom and self harming no shame just stating for clarity and only allowing me In to calm her down he knocks her up but we dont know it at the time I m sterile from birth because mom smoked and drank while pregnant its caused other relationships to end which is why I got tested because having a kid wasnt working out and she starts getting really sick he takes her to hospital while I m at work and i get a call saying he lost her she freaked out and had an argument and let her walk off in a major city by herself in a delirious state and she gets lost and almost snatched but she goes knocking on doors and a stranger helps her back. A day or two later upset at him she goes through his laptop and desktop. First she finds out he cheated on her with other people and then she finds gigs of .... well some shit you just cant fucking unsee. It s all I can do not to kill the bastard and I feel sick af about everything she blows up his Facebook he comes home immediately wipes hard drives and destroys computers while we pack up and gtfo.Queue Feb of it s already been the most insane shit I ve ever been apart of in my life but she has me hooked and convinced we need eachother. We move up to Trucker guys hometown and he helps us get set up before she starts getting really sick again we hadn t been eating well at this point because money got drained away by her needing weed bills and ex guy being literal garbage so we take her to a hospital there she finds out shes months pregnant and insists on abortion because it s ex guys kid and hes a pedo. I personally do not support abortion myself but I do believe in your body your choice. We end up going to the wrong clinic and it gets botched she almost bleeds out but makes it recovery is long and I spend the next few months keeping the house somewhat clean I ve been the only one cleaning since this started and we have a backyard now so I lax on walking the dogs. Meanwhile with no vehicle I ve found a job . miles away from the house at a mcdonalds and it s the best I can do but I m walking there and back every day and I start losing steam on keeping up with the housework solo while she recovers for the next months evidently in this time I catch her flirting with other guys online and lying to me about things she also caught me apologizing to my previous ex in secret because with what I ve let go at this point breaking up with her and deucing seemed pretty shit.Shes not getting periods at this point something is wrong not pregnancy some super rare shit where uterine tissue turns into bone and it blocks the way. So she has to have another surgery around this time last year they fail at fixing it and retry successfully a few weeks later and she has to have a catheter for a week in this time period she told me shed leave if I didnt let her have an open relationship and I caved because I have problems and we ve already been through so much and she still talks about suicide. I say it s okay as long as I m informed involved and she starts acting shady. I had work the day of the first surgery and I came home and had a weird feeling after some recent arguments about her suddenly telling me shes poly and how I m not meeting her needs but she doesnt want to have sex at this point because pain ex trauma etc. And I find out shes been lying to me about video chatting with a guy who bought her a vibrator and she was sexting him the whole time and logs prior to her getting me to agree to the open relationship thing meanwhile i have no desire to pursue anyone else I have enough to deal with so I send her a text saying we need to talk and she flips out and says I m a piece of shit for causing her anxiety when she just had surgery and it turns into the first of many terrible arguments where she turns everything around on me. Christmas eve me and trucker guy have been making trips to Colorado to get her weed the red a horrible blizzard hes a dumbass and I warn him to slow down and we get into an almost fatal wreck with the trailer of a semi trucks totaled hes fine I have bruised ribs from bouncing off center console get a Ford f if you wanna feel safe lol we have to jump through some hoops but we make it home in time for xmas a few days later shes picking fights about me walking the dogs or doing housework because she just had surgery but I m still going to my new job at a phone store making more money and supporting us both with bruised ribs which is agony in and of itself fast forward there s alot of fights she starts over minor shit like housework and how I promised to take care of her like every few days from now on. March th am.... I get a sudden call from my younger sister our mother isnt waking up.. a few days later and full of mixed emotions she was an abusive narcissist who would steal the adderall I was prescribed as a kid but was also extremely sweet and loving at times I m standing at her funeral...we had not talked in almost a year and the last time was before I went to help this girl in Canada and it was a nasty argument where she told me not to come back when this one screwed me over too.... I come back she starts a fight over why I even went to my mother s funeral insinuated that I was cheating on her with my sister and the usual chore shit to which I d naturally be very frustrated but yet the most I d do was raise my voice and then shed start calling me abusive saying she was going back to Canada tell me she hates me and then these fights would end with her blaming it on ptsd or the xanax she was now being prescribed for the anxiety she now had. Meanwhile in the next month shes getting money from a guy she says shes doing art for and then I go to check the time on our tablet one morning and what do I see Her sending nudes to the guy so I talk to him after arguing with her and her telling me it was just and blaming it on taking an extra xanax . mg btw and he informs me he had no idea I didnt know she told him it was open and that I was aware but shed sent him or so since fucking January when I almost DIED getting her medicine so I m livid I say I m leaving she convinces me he was exaggerating to break us up and somehow convinces me to stay at this point you d think shed help with housework I mean my mom died and she cheated on me right No she keeps starting arguments and blame shifting until....A week ago shes drinking and mixing that with her xanax I m depressed and enabling it because i want to drink anyways and anytime I suggest she not she says I m calling her an alcoholic and convincing her I m abusive I ve noticed shes started being real friendly with her ex from like years ago who lives in the same town as trucker guy and who we ve been friends with. She drops the Info that he told her hes got k saved up but not to tell anyone else. She starts spiraling out and I m consoling her in my arms as she cries about her abusive father and the things he did when suddenly she starts talking about how shes doing everything on her own shes a Canadian citizen who has overstayed by well over a year now and cant have a job and she has done housework ie picking up dog pop or vacuuming or walking her two dogs maybe a handful of times and she refuses to do laundry and did dishes maybe twice yes I kept score after her starting numerous arguments about it I try to defuse it by saying woah hey now babe that s not true to which she says fuck you you asshole and moves away from me across the room. I m really tired of these arguments at this point because they all go the same way so I grab the cigarettes and slam the door a bit on the way outside to smoke because I m frustrated at constantly being put down when I work my ass off to support her and her bad habits and try to make her comfortable and be as supportive as i can until she starts attacking me. She locked me outside in degree weather with nothing but a light coat and pajamas on luckily I always keep my keys in my coat so I let myself back in and dont say a word to her as I go and sit at my desk and she cussed me out and berates me as I walk by eventually I turn around in my chair as she continues and say Alright love I really think you ve had too much to drink to which she responds by threatening to call the police and have me removed from the house solely I am paying for. The fight escalated from there to her calling and crying to her trucker friend as I angrily tried to explain how fucked up that all was and how you shouldnt do that to people you care about which he remained Switzerland about despite her trying to convince him I was somehow being the abusive one eventually the fight Peter s out in typical fashion she apologizes for her behavior I say I m fine with just chalking it up to alcohol and xanax being a bad combo.She brings the fight back up each night and cuts me down to the point where I dont even argue anymore I just go to bed and cry myself to sleep the next few days.Day before yesterday I wake her up to kiss her goodbye before I head to work. She snaps at me so I apologize for waking her up and head to work walking still because shes been draining our money dry every paycheck so I still dont have a car. She spam calls my phone times belittles me over text and makes alot of passive aggressive comments while saying that I left while she was talking in a different room and I would have been late otherwise which makes me passive aggressive and rude according to her. Argue a bit over text I get busy actually doing my job spend the rest of my shift explaining how I d like to talk things out when were both sober and that i haven t felt so great about the way things have been going. She suddenly tells me we cant talk tonight because shes not sober and implies I was calling her an alcoholic. She then starts sending me lewd texts and I realize trucker guy and year ago ex are over at our place shes been convincing them to buy her shit and take her on shopping sprees while talking shit about them to me about how they sexualize her I get off work at midnight trucker guy goes home I start drinking because I m hoping we can just chill and hang out.I start noticing her hanging off him she makes sexual comments about how we both better not get any ideas and I point out that shes the only one making things sexual I notice her feel him up and then she makes a joke at my expense about some deeply personal shit so I move to the other room and drink straight out of the bottle because I really do t want to fight I get roped into cooking bacon despite her talking about how she ll do it the right way and just being demeaning so I popped off with some snappy comeback at which point she gets pissed off and starts causing a scene and I try to go off and have a cig Long story short she threatened me with police again admitted to wanting to screw her ex called me inadequate at which point I started screaming shut the fuck up which she recorded so I deduced off to bed while she acted hurt. I woke up woke her up told her she better start figuring her shit out because I was done sent her some really cutting text messages about taking responsibility for herself told her I hated her at this point for all the shit she put me through packed my shit and deduced and now I m here on my dads couch. But on the way home i learned from a few people that shes had a long history of emotionally manipulating men into supporting her and she hasn t had a job for longer than a few months in years. Am I the asshole for how I left Was enough enough I ve spent the past hours cycling between being pissed and crying.Really sorry if it s TL DR it s been a long two years and I left out a bit but you get the idea.TL DR Canadian gf comes to america amidst fucked up situations in every conceivable way turns out to be an emotionally manipulative liar who has been mooching off people for years.Also she checks this subreddit but I didnt name names she was the one who suggested I come here for perspective.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOafBLGmZh5M",
        "colab_type": "text"
      },
      "source": [
        "That does look like a comment with lots of negative language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLFyNfiSZh5M",
        "colab_type": "text"
      },
      "source": [
        "### Optional assignment: working with sentiment scores\n",
        "\n",
        "You could use these sentiment scores for all kinds of purposes. \n",
        "\n",
        "First, you could look at comments with a high or low sentiment, and see what kinds of topics or concerns are discussed. \n",
        "\n",
        "You could train a Naive Bayes classifier (using the code we used above) to see whether sentiments in the posts tell you anything about what `flair_text` class that post falls under. You could also run a **regression analysis** to see if a post's sentiment score (X) is a predictor for something like the user score it received (y). Please see the additional notebook, I will share, \"5-X Regression\", if you're interested in that.\n",
        "\n",
        "You could also combine it with your **topic modeling** output, if that output is interesting. You could create a column in your DataFrame that tells you the most-associated topic with each post/comment (using the notebook from week 3), then see if certain topics relate to certain sentiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG6RgR-NZh5P",
        "colab_type": "text"
      },
      "source": [
        "## Training a sentiment analyzer using Naive Bayes\n",
        "\n",
        "The problem with unsupervised approaches such as the one above is that they typically have poor performance compared to a supervised approach, where we create the labels ourselves.\n",
        "\n",
        "Let's implement a Naive Bayes Classifier, based on our own sentiment labels. These labels will be based on **whether a commenter evaluates a post positively or negatively**. This requires a training set of samples which have known features and known classes. We can manually label a subset of our comments as positive or negative to form our training set. We will also use a different feature extraction technique this time (rather than using tfidf counts).\n",
        "\n",
        "So we need to:\n",
        "\n",
        "1. Create our own sentiment labels for part of our dataset, based on clear rules;\n",
        "2. Apply feature extraction techniques;\n",
        "3. Train a classifier for those labels, which we'll base on feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e47vDb9iNA1O",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"1-LYy48UhoADWLlZKteH9zQT2myxQLiDC\"})   \n",
        "downloaded.GetContentFile('amita-comments_small.csv')"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8rMN8u6PNA1S",
        "colab": {}
      },
      "source": [
        "# load into df\n",
        "df_com = pd.read_csv(\"amita-comments_small.csv\", lineterminator='\\n')"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn3XOMNrZOo1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "972da1b8-2b45-44f6-9c9a-17a66280d76c"
      },
      "source": [
        "# Get rid of empty values and reset index\n",
        "df_com = df_com[~df_com['body'].isin(['[removed]', '[deleted]' ])].dropna(subset=['body']).reset_index(drop=True)\n",
        "len(df_com)"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "506001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jg6mF66Zh5P",
        "colab_type": "text"
      },
      "source": [
        "Let's start labeling ourselves. If you want to be able to classify with some accuracy, you should do **at least a few thousand (!) posts or comments**. This'll take a couple of hours. But you'll have a labeled dataset you can use for all kinds of things!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYIHY7-JZh5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_com_labeled = df_com.iloc[1:1000]"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YTdmL4VTZh5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "8ec61cbb-0c9f-4fc3-d1f8-3d754737856a"
      },
      "source": [
        "df_com_labeled[:5]"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>idint</th>\n",
              "      <th>idstr</th>\n",
              "      <th>created</th>\n",
              "      <th>author</th>\n",
              "      <th>parent</th>\n",
              "      <th>submission</th>\n",
              "      <th>body</th>\n",
              "      <th>score</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>distinguish</th>\n",
              "      <th>textlen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3000001</td>\n",
              "      <td>31784940951</td>\n",
              "      <td>t1_elnxlef</td>\n",
              "      <td>1556120493</td>\n",
              "      <td>NotAllThere_67</td>\n",
              "      <td>t1_eln480s</td>\n",
              "      <td>t3_bgmg0t</td>\n",
              "      <td>I agree that he shouldn't have reacted that wa...</td>\n",
              "      <td>2</td>\n",
              "      <td>AmItheAsshole</td>\n",
              "      <td>NaN</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3000002</td>\n",
              "      <td>31784941007</td>\n",
              "      <td>t1_elnxlfz</td>\n",
              "      <td>1556120494</td>\n",
              "      <td>AutoModerator</td>\n",
              "      <td>t3_bgw50s</td>\n",
              "      <td>t3_bgw50s</td>\n",
              "      <td>^^^^AUTOMOD  ***The following is a copy of the...</td>\n",
              "      <td>1</td>\n",
              "      <td>AmItheAsshole</td>\n",
              "      <td>moderator</td>\n",
              "      <td>876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3000003</td>\n",
              "      <td>31784941015</td>\n",
              "      <td>t1_elnxlg7</td>\n",
              "      <td>1556120494</td>\n",
              "      <td>nuclearwinterxxx</td>\n",
              "      <td>t3_bgqjrp</td>\n",
              "      <td>t3_bgqjrp</td>\n",
              "      <td>NTA, what is this, high school? That's just so...</td>\n",
              "      <td>1</td>\n",
              "      <td>AmItheAsshole</td>\n",
              "      <td>NaN</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3000004</td>\n",
              "      <td>31784941022</td>\n",
              "      <td>t1_elnxlge</td>\n",
              "      <td>1556120494</td>\n",
              "      <td>AutoModerator</td>\n",
              "      <td>t3_bgw50s</td>\n",
              "      <td>t3_bgw50s</td>\n",
              "      <td>\\nIf you want your comment to count toward jud...</td>\n",
              "      <td>1</td>\n",
              "      <td>AmItheAsshole</td>\n",
              "      <td>moderator</td>\n",
              "      <td>822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3000005</td>\n",
              "      <td>31784941178</td>\n",
              "      <td>t1_elnxlkq</td>\n",
              "      <td>1556120497</td>\n",
              "      <td>illini02</td>\n",
              "      <td>t1_elnw2bs</td>\n",
              "      <td>t3_bgndwy</td>\n",
              "      <td>Ok, cool.  Thanks for the clarification.  So t...</td>\n",
              "      <td>1</td>\n",
              "      <td>AmItheAsshole</td>\n",
              "      <td>NaN</td>\n",
              "      <td>356</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0        idint       idstr  ...      subreddit distinguish textlen\n",
              "1     3000001  31784940951  t1_elnxlef  ...  AmItheAsshole         NaN     192\n",
              "2     3000002  31784941007  t1_elnxlfz  ...  AmItheAsshole   moderator     876\n",
              "3     3000003  31784941015  t1_elnxlg7  ...  AmItheAsshole         NaN     144\n",
              "4     3000004  31784941022  t1_elnxlge  ...  AmItheAsshole   moderator     822\n",
              "5     3000005  31784941178  t1_elnxlkq  ...  AmItheAsshole         NaN     356\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agTZddYKLI4g",
        "colab_type": "text"
      },
      "source": [
        "Now, we'll loop over the rows and display the post for each row, and ask the user to label it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BDuuduo1Zh5T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "02cfe1b2-b321-4aef-cfbf-16bf41ed663b"
      },
      "source": [
        "# Classifications:\n",
        "# p: overall positive evaluation of OP\n",
        "# n: overall negative evaluation of OP\n",
        "# x: cannot determine evaluation of OP, or comment is made by OP\n",
        "\n",
        "for index, row in df_com_labeled.iterrows():\n",
        "    print(row.body)\n",
        "    df_com_labeled.loc[index, 'sentiment'] = input()\n",
        "    clear_output()"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I agree that he shouldn't have reacted that way. My judgement is definitely ESH. \n",
            "\n",
            "But she is more of an asshole, imo.\n",
            "She was way out of line, *especially* given the difficulty they have had.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-214-e16bb8122f59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_com_labeled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdf_com_labeled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO-iu-OBWAfZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "e0cf8e7b-4d71-40d3-f6b6-781d6d36cfe1"
      },
      "source": [
        "df_com_labeled[:5]"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>idint</th>\n",
              "      <th>idstr</th>\n",
              "      <th>created</th>\n",
              "      <th>author</th>\n",
              "      <th>parent</th>\n",
              "      <th>submission</th>\n",
              "      <th>body</th>\n",
              "      <th>score</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>distinguish</th>\n",
              "      <th>textlen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3000001</td>\n",
              "      <td>31784940951</td>\n",
              "      <td>t1_elnxlef</td>\n",
              "      <td>1556120493</td>\n",
              "      <td>NotAllThere_67</td>\n",
              "      <td>t1_eln480s</td>\n",
              "      <td>t3_bgmg0t</td>\n",
              "      <td>I agree that he shouldn't have reacted that wa...</td>\n",
              "      <td>2</td>\n",
              "      <td>AmItheAsshole</td>\n",
              "      <td>NaN</td>\n",
              "      <td>192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3000002</td>\n",
              "      <td>31784941007</td>\n",
              "      <td>t1_elnxlfz</td>\n",
              "      <td>1556120494</td>\n",
              "      <td>AutoModerator</td>\n",
              "      <td>t3_bgw50s</td>\n",
              "      <td>t3_bgw50s</td>\n",
              "      <td>^^^^AUTOMOD  ***The following is a copy of the...</td>\n",
              "      <td>1</td>\n",
              "      <td>AmItheAsshole</td>\n",
              "      <td>moderator</td>\n",
              "      <td>876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3000003</td>\n",
              "      <td>31784941015</td>\n",
              "      <td>t1_elnxlg7</td>\n",
              "      <td>1556120494</td>\n",
              "      <td>nuclearwinterxxx</td>\n",
              "      <td>t3_bgqjrp</td>\n",
              "      <td>t3_bgqjrp</td>\n",
              "      <td>NTA, what is this, high school? That's just so...</td>\n",
              "      <td>1</td>\n",
              "      <td>AmItheAsshole</td>\n",
              "      <td>NaN</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3000004</td>\n",
              "      <td>31784941022</td>\n",
              "      <td>t1_elnxlge</td>\n",
              "      <td>1556120494</td>\n",
              "      <td>AutoModerator</td>\n",
              "      <td>t3_bgw50s</td>\n",
              "      <td>t3_bgw50s</td>\n",
              "      <td>\\nIf you want your comment to count toward jud...</td>\n",
              "      <td>1</td>\n",
              "      <td>AmItheAsshole</td>\n",
              "      <td>moderator</td>\n",
              "      <td>822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3000005</td>\n",
              "      <td>31784941178</td>\n",
              "      <td>t1_elnxlkq</td>\n",
              "      <td>1556120497</td>\n",
              "      <td>illini02</td>\n",
              "      <td>t1_elnw2bs</td>\n",
              "      <td>t3_bgndwy</td>\n",
              "      <td>Ok, cool.  Thanks for the clarification.  So t...</td>\n",
              "      <td>1</td>\n",
              "      <td>AmItheAsshole</td>\n",
              "      <td>NaN</td>\n",
              "      <td>356</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0        idint       idstr  ...      subreddit distinguish textlen\n",
              "1     3000001  31784940951  t1_elnxlef  ...  AmItheAsshole         NaN     192\n",
              "2     3000002  31784941007  t1_elnxlfz  ...  AmItheAsshole   moderator     876\n",
              "3     3000003  31784941015  t1_elnxlg7  ...  AmItheAsshole         NaN     144\n",
              "4     3000004  31784941022  t1_elnxlge  ...  AmItheAsshole   moderator     822\n",
              "5     3000005  31784941178  t1_elnxlkq  ...  AmItheAsshole         NaN     356\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91Im7zboZh5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save your labels to csv\n",
        "df_com_labeled.to_csv('df_com_Sentiment_Labeled.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeQMd8r_Zh5W",
        "colab_type": "text"
      },
      "source": [
        "(I've cheated here and randomly assigned some tags to the corpus in the cell below, just so you can see how this works)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7gqnjajZh5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags = ['p', 'n', 'x']\n",
        "df_com_labeled[\"sentiment\"] = np.random.choice(tags, 999, p=[0.3, 0.6, 0.1])"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOPh8KLGZh5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_com_labeled = df_com_labeled.reset_index(drop=True)"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "360smjSoZh5c",
        "colab_type": "text"
      },
      "source": [
        "### Train, test, and cross-validation sets\n",
        "\n",
        "When building our sentiment analyzer, we need to create a test set again, in order to prevent overestimating its performance and overconstraining it. We will use the test set to evaluate the performance of our sentiment analyzer once it is complete.\n",
        "\n",
        "When designing our sentiment analyzer, we’ll have a number of choices to make along the way (which were made for us when using VADER). How many features should we use? Should we include the capitalization of words as a feature?  All of these **hyperparameters** will effect the performance of our sentiment analyzer. To maximize performance, it's best to evaluate our classifier under different hyperparameter settings. We could do this with the training set itself – but then we run into the same risk of overconstraining the analyzer that we discussed earlier. Using the test set would mean we'd be tuning our classifier to the test set – defeating the purpose of setting that data aside in the first place.\n",
        "\n",
        "So we'll set another portion of the original training set aside: the **cross-validation** set. We can use it to evaluate the performance of our sentiment analyzer as we tune our hyperparameters. This means the final evaluation of our analyzer’s performance will be a true representation of how it will perform on unlabeled comments from our full collection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaoUY9EeZh5c",
        "colab_type": "text"
      },
      "source": [
        "First, let's have a look at how much we've done"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtM8c38cZh5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c8e30167-2f5b-4bd7-b7a5-1274c78b210f"
      },
      "source": [
        "pos_comments = [(df_com_labeled.loc[row,'body'],'positive') for row in range(len(df_com_labeled)) if \n",
        "              df_com_labeled.loc[row,'sentiment'] == 'p']\n",
        "\n",
        "neg_comments = [(df_com_labeled.loc[row,'body'],'negative') for row in range(len(df_com_labeled)) if \n",
        "              df_com_labeled.loc[row,'sentiment'] == 'n']\n",
        "\n",
        "print('Number of comments labeled positive: %d' % len(pos_comments))\n",
        "print('Number of comments labeled negative: %d' % len(neg_comments))"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of comments labeled positive: 316\n",
            "Number of comments labeled negative: 585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZrz94ppZh5h",
        "colab_type": "text"
      },
      "source": [
        "Note that you see a class imbalance here – we have way more negative than positive labels. This presents a new challenge for our sentiment analyzer. If the probability of seeing positive comments is small, Bayes Theorem is likely to predict that the probability of any comment being positive is small **regardless of the evidence**. So we need to up- or downsample again.\n",
        "\n",
        "The choice of upsampling, downsampling, or randomly sampling (producing the true positive to negative ratio) is a **hyperparameter** of our sentiment analyzer. To know which method will work best, we ought to try all of them and see which yields the best performance on your cross-validation set. \n",
        "\n",
        "For now, we will put half of the positive and negative comments into the **training set** while down sampling negative tweets at a one-to-one ratio. Half of the remaining comments will go into the **cross-validation set**, and the final quarter of comments into the **test set**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNmykxYsZh5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Half of the positive comments go in training\n",
        "# Downsampling the negative comments at 1 pos:1 neg\n",
        "\n",
        "len_train = int(round(len(pos_comments)/2)*2) # Define total len of train set based on len of pos_comments\n",
        "train_comments = pos_comments[:int(len_train/2)] + neg_comments[:int(len_train/2)]\n",
        "\n",
        "# Half of the remaining half go in cv\n",
        "cv_neg_cutoff = int((len_train/2) + round((len(neg_comments) - len_train/2)/2))\n",
        "cv_pos_cutoff = int((len_train/2) + round((len(pos_comments) - len_train/2)/2))\n",
        "cv_comments = neg_comments[int(len_train/2):cv_neg_cutoff] + pos_comments[int(len_train/2):cv_pos_cutoff]  \n",
        "\n",
        "# Rest go into testing\n",
        "test_comments = neg_comments[cv_neg_cutoff:] + pos_comments[cv_pos_cutoff:]  "
      ],
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOEq3z-rZh5k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "71a316db-52ec-4189-de49-28e3634ddd8e"
      },
      "source": [
        "## Test\n",
        "train_comments[7]"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('How is the fear irrational if there was an actual active shooter in the area? Yes the shooter was caught but it still happened. An irrational fear would need to be completely baseless and unlikely.',\n",
              " 'positive')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m61KpDj8Zh5p",
        "colab_type": "text"
      },
      "source": [
        "(Note that you can do this kind of splitting through scikit-learn's `train_test_split()` and `KFold()` methods, making it much easier!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8rANawSZh5q",
        "colab_type": "text"
      },
      "source": [
        "## Feature extraction design\n",
        "\n",
        "Now it's time to define our sentiment analyzer’s features. We'll do so with boolean `contains(word)` statements. For instance, the feature `contains(disagree)` will likely be `True` for a negative comment, and `False` for a positive tweet. We’ll need to construct a list of useful words for this purpose.\n",
        "\n",
        "### Bigrams\n",
        "Note that this is harder than it might seem! If we were to train a model that believes the word “like” indicates a positive tweet, we would misclassify the second tweet. It’s clear that the classifier’s performance would increase if it could recognize that the word “not” is negating the word “like.” One way to address negation markers is to include **bigrams** in our list of features. Doing so allows our classifier to recognize the collocation of words such as “(not,like)” in addition to the typical unigram features we would extract.\n",
        "\n",
        "### Preventing overfit\n",
        "This word list shouldn’t include every word we come across in our collection of comments: using too many uncommon words will cause our sentiment analyzer to *overfit* the training sample. This usually happens when the model is too complex (that is, using too many features compared to the number of observations). Such a model will be very accurate on the training data  not accurate on untrained or new data. \n",
        "\n",
        "We will avoid this issue by requiring that each word **appear a certain number of times** before we consider it as a feature. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2R_UEWcZh5q",
        "colab_type": "text"
      },
      "source": [
        "Let's write a function that applies these feature extraction techniques to our comments. First, we extract a list of unigrams and bigrams. We treat all html URLs as the same “word”, while excluding punctuation and capitalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDnFIjDEZh5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.metrics import BigramAssocMeasures\n",
        "from nltk.collocations import BigramCollocationFinder\n",
        "import string\n",
        "import itertools\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "punct = set(string.punctuation)\n",
        "\n",
        "def filter_comments(comments):\n",
        "    filtered_bigrams = []\n",
        "    for words, sentiment in comments: \n",
        "        words_filtered = []\n",
        "        # Lemmatize using spacy\n",
        "        words = words.lower()\n",
        "        doc = simple_preprocess(str(words), deacc=True)     \n",
        "        words_filtered.extend([token for token in doc])\n",
        "        # Identify top 200 bigams using chi_sq measure of importance\n",
        "        bigram_finder = BigramCollocationFinder.from_words(words_filtered)\n",
        "        bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 200)      \n",
        "        # Add to filtered list\n",
        "        filtered_bigrams.append(([ngram for ngram in itertools.chain(words_filtered,bigrams)],sentiment))\n",
        "    return filtered_bigrams"
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_UGUXOiZh5s",
        "colab_type": "text"
      },
      "source": [
        "The result of the filter is a **list of tuples** for each comment. The first entry in each tuple is a list of unigrams and bigrams for that comment, and the second entry in the tuple is the manually labeled sentiment of that comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3BFjJxcZh5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tuples = filter_comments(train_comments)\n",
        "cv_tuples = filter_comments(cv_comments)\n",
        "test_tuples = filter_comments(test_comments)    "
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAsAEp19Zh5u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8d9dc2b-b873-413b-d625-ac827693abb8"
      },
      "source": [
        "train_tuples[0]"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['agree',\n",
              "  'that',\n",
              "  'he',\n",
              "  'shouldn',\n",
              "  'have',\n",
              "  'reacted',\n",
              "  'that',\n",
              "  'way',\n",
              "  'my',\n",
              "  'judgement',\n",
              "  'is',\n",
              "  'definitely',\n",
              "  'esh',\n",
              "  'but',\n",
              "  'she',\n",
              "  'is',\n",
              "  'more',\n",
              "  'of',\n",
              "  'an',\n",
              "  'asshole',\n",
              "  'imo',\n",
              "  'she',\n",
              "  'was',\n",
              "  'way',\n",
              "  'out',\n",
              "  'of',\n",
              "  'line',\n",
              "  'especially',\n",
              "  'given',\n",
              "  'the',\n",
              "  'difficulty',\n",
              "  'they',\n",
              "  'have',\n",
              "  'had',\n",
              "  ('an', 'asshole'),\n",
              "  ('asshole', 'imo'),\n",
              "  ('definitely', 'esh'),\n",
              "  ('difficulty', 'they'),\n",
              "  ('esh', 'but'),\n",
              "  ('especially', 'given'),\n",
              "  ('given', 'the'),\n",
              "  ('he', 'shouldn'),\n",
              "  ('line', 'especially'),\n",
              "  ('my', 'judgement'),\n",
              "  ('the', 'difficulty'),\n",
              "  ('agree', 'that'),\n",
              "  ('but', 'she'),\n",
              "  ('have', 'had'),\n",
              "  ('have', 'reacted'),\n",
              "  ('imo', 'she'),\n",
              "  ('is', 'definitely'),\n",
              "  ('is', 'more'),\n",
              "  ('judgement', 'is'),\n",
              "  ('more', 'of'),\n",
              "  ('of', 'an'),\n",
              "  ('of', 'line'),\n",
              "  ('out', 'of'),\n",
              "  ('reacted', 'that'),\n",
              "  ('she', 'was'),\n",
              "  ('shouldn', 'have'),\n",
              "  ('that', 'he'),\n",
              "  ('they', 'have'),\n",
              "  ('was', 'way'),\n",
              "  ('way', 'my'),\n",
              "  ('way', 'out'),\n",
              "  ('she', 'is'),\n",
              "  ('that', 'way')],\n",
              " 'positive')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1L87VWyZh5w",
        "colab_type": "text"
      },
      "source": [
        "Remember that we wanted to get rid of the features that do not appear frequently? We'll now remove all unigrams or bigrams that appear less than 3 times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nkzc_gQRZh5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_word_features(comments,min_freq):\n",
        "    word_list = []\n",
        "    for word_or_tuple in comments:\n",
        "        word_list.extend(word_or_tuple[0])\n",
        "    # Count the frequency of each unigram and bigram\n",
        "    freqs = FreqDist(word_list)\n",
        "    # Sort based on frequency\n",
        "    sorted_word_list = sorted(freqs.items(), key=lambda x: x[1], reverse=True)\n",
        "    # Only include features appearing at least min_freq times\n",
        "    word_features = [sorted_word_list[word][0] for word in \n",
        "                     range(len(sorted_word_list)) if sorted_word_list[word][1] >= min_freq]    \n",
        "    # Return list of features\n",
        "    return word_features\n",
        "\n",
        "word_features = get_word_features(train_tuples, 3)"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg-NrYicZh5y",
        "colab_type": "text"
      },
      "source": [
        "Let's see how many features we have found!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2XaBC_FZh50",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b32c7aa5-dcbe-4f40-c8ad-cf34b4829cb9"
      },
      "source": [
        "len(word_features)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1534"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgtUvhEpZh53",
        "colab_type": "text"
      },
      "source": [
        "Now that we have a final list of word features, we can finally evaluate the boolean `contains(word_feature)` statements for each tweet. To do so, we first define an `extract_features()` function that takes a filtered comment as an input, then determines if each word feature exists in the filtered comment’s list of unigrams and bigrams."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJcBp3buZh53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(filtered_comment):\n",
        "    filtered_comment_words = set(filtered_comment)\n",
        "    features = {}\n",
        "    for word in word_features:        \n",
        "        # Check if word feature is present in filtered_comment\n",
        "        features['contains(%s)' % str(word)] = (word in filtered_comment_words)\n",
        "    return features"
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZI1Ko2tZh55",
        "colab_type": "text"
      },
      "source": [
        "The NLTK classify package provides a convenient `.apply_features()` method to apply our `extract_features()` function to each comment in our datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slh4a-LVZh55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set = apply_features(extract_features, train_tuples)\n",
        "cv_set = apply_features(extract_features, cv_tuples)\n",
        "test_set = apply_features(extract_features, test_tuples)"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBe5Nx_uZh58",
        "colab_type": "text"
      },
      "source": [
        "The final result is a NLTK `LazyMap` object that contains a tuple for each comment. The first entry in the tuple is a list of boolean `contains(word)` features for each of the feature words we selected, while the second entry in the tuple is the manually labeled sentiment of the comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwfHfQm4Zh58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y1gopnJZh59",
        "colab_type": "text"
      },
      "source": [
        "## Training the classifier\n",
        "\n",
        "It's Time to train our Naive Bayes Classifier. Let's use NLTK's one this time around.\n",
        "\n",
        "Note that we're using Bayesian classfier over **binary features** this time: that is, we use a bunch of boolean `contains()` variables that tell our classifier whether or not some feature is present in a comment. The equivalent in sklearn for this is the `BernoulliNB` classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azOLyVO9Zh5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = NaiveBayesClassifier.train(training_set)"
      ],
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOIk4_iGZh5_",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "To accurately evaluate the performance of our classifier, we have to look at 2 things: **precision** and **recall**.\n",
        "\n",
        "- **Precision:** the number of true positives (correctly labeled items) divided by the sum of true positives and false positives (incorrectly labeled items)\n",
        "- **Recall:** the number of true positives divided by the total number of elements that actually belong to the positive class (i.e., the sum of true positives and false negatives).\n",
        "\n",
        "We can average the precision and recall metrics using their harmonic mean, producing a quantity known as the F1 score. It's a measure of a test's total accuracy. See https://en.wikipedia.org/wiki/F1_score for more.\n",
        "\n",
        "We'll use a function that evaluates our classifier, based on the cross-validation set we created earlier. We'll calculate F1, precision and recall scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYlJ092JZh6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_classifier(data_set):\n",
        "    # NLTK .accuracy method calculates accuracy\n",
        "    cross_valid_accuracy = accuracy(classifier, data_set)\n",
        "\n",
        "    # Create two sets to count positive and negative comments\n",
        "    ref_set = collections.defaultdict(set)\n",
        "    obs_set = collections.defaultdict(set)\n",
        "\n",
        "    # Loop over each comment in our cross validation set\n",
        "    for i, (feats, label) in enumerate(data_set):\n",
        "\n",
        "        #Classify the comment by feeding the classifier the comment's features\n",
        "        observed = classifier.classify(feats)\n",
        "\n",
        "        #Add the current comment to the \"reference\" set under the actual class\n",
        "        ref_set[label].add(i)\n",
        "\n",
        "        #Add the current coment to the \"observation\" set under the predicted class\n",
        "        obs_set[observed].add(i)\n",
        "\n",
        "    # Calculate F score, precision, an recall for positive and negative labels\n",
        "    print ('Accuracy:', cross_valid_accuracy)\n",
        "    print ('F-measure [negative]:', fmeas(ref_set['negative'], obs_set['negative']))\n",
        "    print ('F-measure [positive]:', fmeas(ref_set['positive'], obs_set['positive']))\n",
        "    print ('Precision [negative]:', prec(ref_set['negative'], obs_set['negative']))\n",
        "    print ('Precision [positive]:', prec(ref_set['positive'], obs_set['positive']))\n",
        "    rec_neg=rec(ref_set['negative'], obs_set['negative'])\n",
        "    rec_pos=rec(ref_set['positive'], obs_set['positive'])\n",
        "    print ('Recall [negative]:', rec_neg)\n",
        "    print ('Recall [positive]:', rec_pos)\n",
        "    total_neg=len(neg_comments)\n",
        "    total_pos=len(pos_comments)"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2jyUjj1rZh6B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4a7441e9-29da-49f5-a687-018df8464a72"
      },
      "source": [
        "eval_classifier(cv_set) "
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.4232081911262799\n",
            "F-measure [negative]: 0.46006389776357826\n",
            "F-measure [positive]: 0.38095238095238093\n",
            "Precision [negative]: 0.7272727272727273\n",
            "Precision [positive]: 0.26804123711340205\n",
            "Recall [negative]: 0.3364485981308411\n",
            "Recall [positive]: 0.6582278481012658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWX9jXceZh6E",
        "colab_type": "text"
      },
      "source": [
        "At this point, we have to see if we are happy with the outcome of our performance metrics. \n",
        "If not, we need to change the hyperparameters of our classifier and revaluate its performance on our cross-validation set. As noted, we may want to consider limiting our classifier to **high-information features**. We can check what these features are using NLTK’s `show_most_informative_features()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "s5UN9b4lZh6E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3c905c6a-f56a-4bfb-8cef-42aa53e0f9e4"
      },
      "source": [
        "print(classifier.show_most_informative_features(5))"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            " contains(('of', 'you')) = True           positi : negati =      5.7 : 1.0\n",
            "           contains(dad) = True           negati : positi =      5.7 : 1.0\n",
            "     contains(situation) = True           negati : positi =      5.0 : 1.0\n",
            "         contains(these) = True           negati : positi =      5.0 : 1.0\n",
            "         contains(often) = True           negati : positi =      5.0 : 1.0\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ0u-rfmZh6F",
        "colab_type": "text"
      },
      "source": [
        "We can use these features in the *feature extraction design* step above to see if it will improve our model (which it won't necessarily will). **The goal is, through tweaking our hyperparameters like this, to improve the accuracy of our model.** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jddy_7cMZh6F",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating on the test set\n",
        "\n",
        "It's only after tweaking our model for a while that we should crack open our test set and see how well our classifier has done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOQtSampZh6G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1d5f37d5-5e00-468f-f5b7-503e9ca51fe8"
      },
      "source": [
        "eval_classifier(test_set)"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.4246575342465753\n",
            "F-measure [negative]: 0.4473684210526316\n",
            "F-measure [positive]: 0.4\n",
            "Precision [negative]: 0.7472527472527473\n",
            "Precision [positive]: 0.27860696517412936\n",
            "Recall [negative]: 0.3192488262910798\n",
            "Recall [positive]: 0.7088607594936709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TafGz4uTZh6I",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion: Data analysis and hermeneutics\n",
        "\n",
        "That was a lot! Again, don't worry if you didn't understand every part of this notebook. Its main purpose is for you to get a first look into the many ways in which data scientists can classify their data.\n",
        "\n",
        "There's a lot you can do with the methods we've applied here. For instance, you can use classification to try and find binaries in your dataset. You could tag a corpus manually, based on the presence of some binary category X or Y that you deem important. You could also create a set of categories based on, say, particular word frequencies. Then you can create a classifier to see if you can successfully predict these categories in other texts.\n",
        "\n",
        "You can use classification, feature extraction and sentiment analysis to explore your own data. For instance:\n",
        "- Using sentiment scores to trace posts or topics of interest;\n",
        "- Using feature extraction to create new classes; \n",
        "- Training a classifier based on your own classes (e.g. the presence of a specific topic you're interested in)."
      ]
    }
  ]
}